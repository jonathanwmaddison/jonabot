================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2025-02-03T16:07:11.861Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
public/
  file.svg
  globe.svg
  huggingface-logo.svg
  jonathan-maddison-resume.pdf
  next.svg
  vercel.svg
  window.svg
src/
  app/
    api/
      chat/
        route.ts
      contact/
        route.ts
      feedback/
        route.ts
      huggingface-chat/
        route.ts
      resume/
        route.ts
    components/
      Chat/
        Avatar.tsx
        ChatContext.tsx
        ChatInput.tsx
        ChatWindow.tsx
        CommandSuggestions.tsx
        ContactForm.tsx
        LoadingSkeleton.tsx
        MessageBubble.tsx
        SuggestedPrompts.tsx
        TypingIndicator.tsx
      Games/
        Pong.tsx
      MatrixRain.tsx
      Snow.tsx
      ThemeToggle.tsx
    huggingface/
      page.tsx
    resume/
      page.tsx
    globals.css
    icon.tsx
    layout.tsx
    page.tsx
    providers.tsx
    theme.config.ts
    theme.ts
  lib/
    basePrompt.ts
    commandFunctions.ts
    commandHandler.ts
    commands.ts
    huggingFacePrompt.ts
    openai.ts
    projectHighlights.ts
    resumeData.ts
    utils.ts
    weaknessData.ts
.eslintrc.json
.gitignore
03-guidance.md
bug-fix_URLS_AND_COMMANDS.md
HuggingFaceChat.md
Matrix_mode.md
MOBILE_RESPONSIVENESS_ISSUE.md
next.config.js
package.json
PROJECT_OVERVIEW.md
README.md
TECHNICAL_SPEC.md
tsconfig.json
WORK_LOG.md

================================================================
Repository Files
================================================================

================
File: public/file.svg
================
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>

================
File: public/globe.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>

================
File: public/huggingface-logo.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="95" height="88" fill="none">
	<path fill="#FFD21E" d="M47.21 76.5a34.75 34.75 0 1 0 0-69.5 34.75 34.75 0 0 0 0 69.5Z" />
	<path
		fill="#FF9D0B"
		d="M81.96 41.75a34.75 34.75 0 1 0-69.5 0 34.75 34.75 0 0 0 69.5 0Zm-73.5 0a38.75 38.75 0 1 1 77.5 0 38.75 38.75 0 0 1-77.5 0Z"
	/>
	<path
		fill="#3A3B45"
		d="M58.5 32.3c1.28.44 1.78 3.06 3.07 2.38a5 5 0 1 0-6.76-2.07c.61 1.15 2.55-.72 3.7-.32ZM34.95 32.3c-1.28.44-1.79 3.06-3.07 2.38a5 5 0 1 1 6.76-2.07c-.61 1.15-2.56-.72-3.7-.32Z"
	/>
	<path
		fill="#FF323D"
		d="M46.96 56.29c9.83 0 13-8.76 13-13.26 0-2.34-1.57-1.6-4.09-.36-2.33 1.15-5.46 2.74-8.9 2.74-7.19 0-13-6.88-13-2.38s3.16 13.26 13 13.26Z"
	/>
	<path
		fill="#3A3B45"
		fill-rule="evenodd"
		d="M39.43 54a8.7 8.7 0 0 1 5.3-4.49c.4-.12.81.57 1.24 1.28.4.68.82 1.37 1.24 1.37.45 0 .9-.68 1.33-1.35.45-.7.89-1.38 1.32-1.25a8.61 8.61 0 0 1 5 4.17c3.73-2.94 5.1-7.74 5.1-10.7 0-2.34-1.57-1.6-4.09-.36l-.14.07c-2.31 1.15-5.39 2.67-8.77 2.67s-6.45-1.52-8.77-2.67c-2.6-1.29-4.23-2.1-4.23.29 0 3.05 1.46 8.06 5.47 10.97Z"
		clip-rule="evenodd"
	/>
	<path
		fill="#FF9D0B"
		d="M70.71 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM24.21 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM17.52 48c-1.62 0-3.06.66-4.07 1.87a5.97 5.97 0 0 0-1.33 3.76 7.1 7.1 0 0 0-1.94-.3c-1.55 0-2.95.59-3.94 1.66a5.8 5.8 0 0 0-.8 7 5.3 5.3 0 0 0-1.79 2.82c-.24.9-.48 2.8.8 4.74a5.22 5.22 0 0 0-.37 5.02c1.02 2.32 3.57 4.14 8.52 6.1 3.07 1.22 5.89 2 5.91 2.01a44.33 44.33 0 0 0 10.93 1.6c5.86 0 10.05-1.8 12.46-5.34 3.88-5.69 3.33-10.9-1.7-15.92-2.77-2.78-4.62-6.87-5-7.77-.78-2.66-2.84-5.62-6.25-5.62a5.7 5.7 0 0 0-4.6 2.46c-1-1.26-1.98-2.25-2.86-2.82A7.4 7.4 0 0 0 17.52 48Zm0 4c.51 0 1.14.22 1.82.65 2.14 1.36 6.25 8.43 7.76 11.18.5.92 1.37 1.31 2.14 1.31 1.55 0 2.75-1.53.15-3.48-3.92-2.93-2.55-7.72-.68-8.01.08-.02.17-.02.24-.02 1.7 0 2.45 2.93 2.45 2.93s2.2 5.52 5.98 9.3c3.77 3.77 3.97 6.8 1.22 10.83-1.88 2.75-5.47 3.58-9.16 3.58-3.81 0-7.73-.9-9.92-1.46-.11-.03-13.45-3.8-11.76-7 .28-.54.75-.76 1.34-.76 2.38 0 6.7 3.54 8.57 3.54.41 0 .7-.17.83-.6.79-2.85-12.06-4.05-10.98-8.17.2-.73.71-1.02 1.44-1.02 3.14 0 10.2 5.53 11.68 5.53.11 0 .2-.03.24-.1.74-1.2.33-2.04-4.9-5.2-5.21-3.16-8.88-5.06-6.8-7.33.24-.26.58-.38 1-.38 3.17 0 10.66 6.82 10.66 6.82s2.02 2.1 3.25 2.1c.28 0 .52-.1.68-.38.86-1.46-8.06-8.22-8.56-11.01-.34-1.9.24-2.85 1.31-2.85Z"
	/>
	<path
		fill="#FFD21E"
		d="M38.6 76.69c2.75-4.04 2.55-7.07-1.22-10.84-3.78-3.77-5.98-9.3-5.98-9.3s-.82-3.2-2.69-2.9c-1.87.3-3.24 5.08.68 8.01 3.91 2.93-.78 4.92-2.29 2.17-1.5-2.75-5.62-9.82-7.76-11.18-2.13-1.35-3.63-.6-3.13 2.2.5 2.79 9.43 9.55 8.56 11-.87 1.47-3.93-1.71-3.93-1.71s-9.57-8.71-11.66-6.44c-2.08 2.27 1.59 4.17 6.8 7.33 5.23 3.16 5.64 4 4.9 5.2-.75 1.2-12.28-8.53-13.36-4.4-1.08 4.11 11.77 5.3 10.98 8.15-.8 2.85-9.06-5.38-10.74-2.18-1.7 3.21 11.65 6.98 11.76 7.01 4.3 1.12 15.25 3.49 19.08-2.12Z"
	/>
	<path
		fill="#FF9D0B"
		d="M77.4 48c1.62 0 3.07.66 4.07 1.87a5.97 5.97 0 0 1 1.33 3.76 7.1 7.1 0 0 1 1.95-.3c1.55 0 2.95.59 3.94 1.66a5.8 5.8 0 0 1 .8 7 5.3 5.3 0 0 1 1.78 2.82c.24.9.48 2.8-.8 4.74a5.22 5.22 0 0 1 .37 5.02c-1.02 2.32-3.57 4.14-8.51 6.1-3.08 1.22-5.9 2-5.92 2.01a44.33 44.33 0 0 1-10.93 1.6c-5.86 0-10.05-1.8-12.46-5.34-3.88-5.69-3.33-10.9 1.7-15.92 2.78-2.78 4.63-6.87 5.01-7.77.78-2.66 2.83-5.62 6.24-5.62a5.7 5.7 0 0 1 4.6 2.46c1-1.26 1.98-2.25 2.87-2.82A7.4 7.4 0 0 1 77.4 48Zm0 4c-.51 0-1.13.22-1.82.65-2.13 1.36-6.25 8.43-7.76 11.18a2.43 2.43 0 0 1-2.14 1.31c-1.54 0-2.75-1.53-.14-3.48 3.91-2.93 2.54-7.72.67-8.01a1.54 1.54 0 0 0-.24-.02c-1.7 0-2.45 2.93-2.45 2.93s-2.2 5.52-5.97 9.3c-3.78 3.77-3.98 6.8-1.22 10.83 1.87 2.75 5.47 3.58 9.15 3.58 3.82 0 7.73-.9 9.93-1.46.1-.03 13.45-3.8 11.76-7-.29-.54-.75-.76-1.34-.76-2.38 0-6.71 3.54-8.57 3.54-.42 0-.71-.17-.83-.6-.8-2.85 12.05-4.05 10.97-8.17-.19-.73-.7-1.02-1.44-1.02-3.14 0-10.2 5.53-11.68 5.53-.1 0-.19-.03-.23-.1-.74-1.2-.34-2.04 4.88-5.2 5.23-3.16 8.9-5.06 6.8-7.33-.23-.26-.57-.38-.98-.38-3.18 0-10.67 6.82-10.67 6.82s-2.02 2.1-3.24 2.1a.74.74 0 0 1-.68-.38c-.87-1.46 8.05-8.22 8.55-11.01.34-1.9-.24-2.85-1.31-2.85Z"
	/>
	<path
		fill="#FFD21E"
		d="M56.33 76.69c-2.75-4.04-2.56-7.07 1.22-10.84 3.77-3.77 5.97-9.3 5.97-9.3s.82-3.2 2.7-2.9c1.86.3 3.23 5.08-.68 8.01-3.92 2.93.78 4.92 2.28 2.17 1.51-2.75 5.63-9.82 7.76-11.18 2.13-1.35 3.64-.6 3.13 2.2-.5 2.79-9.42 9.55-8.55 11 .86 1.47 3.92-1.71 3.92-1.71s9.58-8.71 11.66-6.44c2.08 2.27-1.58 4.17-6.8 7.33-5.23 3.16-5.63 4-4.9 5.2.75 1.2 12.28-8.53 13.36-4.4 1.08 4.11-11.76 5.3-10.97 8.15.8 2.85 9.05-5.38 10.74-2.18 1.69 3.21-11.65 6.98-11.76 7.01-4.31 1.12-15.26 3.49-19.08-2.12Z"
	/>
</svg>

================
File: public/next.svg
================
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>

================
File: public/vercel.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>

================
File: public/window.svg
================
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>

================
File: src/app/api/chat/route.ts
================
import { OpenAIStream, StreamingTextResponse, MODELS } from '@/lib/openai';
import { getBasePrompt } from '@/lib/basePrompt';
import { NextRequest } from 'next/server';
import { waitUntil } from '@vercel/functions';

// // Configure the function
// export const runtime = 'nodejs';
// export const maxDuration = 60; // Maximum duration in seconds
// export const dynamic = 'force-dynamic'; // Ensure the route is dynamic

export async function POST(req: NextRequest) {
  const startTime = Date.now();
  console.log('Request received');
  try {
    // Verify content type
    const contentType = req.headers.get('content-type');
    if (!contentType?.includes('application/json')) {
      return new Response('Invalid content type. Expected application/json', { 
        status: 415 
      });
    }

    const { userMessages } = await req.json();
    
    if (!Array.isArray(userMessages)) {
      return new Response('Invalid request: userMessages must be an array', { 
        status: 400,
        headers: {
          'Content-Type': 'application/json'
        }
      });
    }

    const finalMessages = [
      { role: 'system', content: getBasePrompt() },
      ...userMessages,
    ];

    const stream = await OpenAIStream({
      model: MODELS.GPT_4,
      messages: finalMessages,
      temperature: 0.7,
    });

    // Log request details after sending response
    waitUntil(
      (async () => {
        const duration = Date.now() - startTime;
        console.log(`Chat request processed in ${duration}ms`, {
          messagesCount: userMessages.length,
          region: process.env.VERCEL_REGION
        });
      })()
    );

    return new StreamingTextResponse(stream);
  } catch (error) {
    console.error('Chat error:', error);
    
    // Return a more detailed error response
    return new Response(
      JSON.stringify({
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Unknown error occurred'
      }), 
      { 
        status: 500,
        headers: {
          'Content-Type': 'application/json'
        }
      }
    );
  }
}

================
File: src/app/api/contact/route.ts
================
import { NextRequest, NextResponse } from 'next/server';
import nodemailer from 'nodemailer';

// Ensure this route runs in a Node.js environment (not Edge)
export const runtime = 'nodejs';

// Simple in-memory rate limiting (Note: This state is not shared between serverless instances)
const RATE_LIMIT_WINDOW = 3600000; // 1 hour in milliseconds
const MAX_EMAILS_PER_WINDOW = 3; // Max 3 emails per hour
const emailLog = new Map<string, number[]>();

function isRateLimited(identifier: string): boolean {
  const now = Date.now();
  const userEmails = emailLog.get(identifier) || [];
  
  // Clean up old entries
  const recentEmails = userEmails.filter(timestamp => now - timestamp < RATE_LIMIT_WINDOW);
  
  if (recentEmails.length >= MAX_EMAILS_PER_WINDOW) {
    return true;
  }
  
  // Update the log with the new email timestamp
  emailLog.set(identifier, [...recentEmails, now]);
  return false;
}

// Create a nodemailer transporter using Gmail SMTP
const transporter = nodemailer.createTransport({
  service: 'gmail',
  auth: {
    user: process.env.GMAIL_USER,
    pass: process.env.GMAIL_APP_PASSWORD,
  },
});

export async function POST(req: NextRequest) {
  try {
    console.log('Contact API called');

    // Extract client IP from the x-forwarded-for header (if available)
    const forwardedFor = req.headers.get('x-forwarded-for');
    const identifier = forwardedFor ? forwardedFor.split(',')[0].trim() : 'unknown';

    // Check rate limit for this IP
    if (isRateLimited(identifier)) {
      console.log('Rate limit exceeded for:', identifier);
      return NextResponse.json(
        { error: 'Too many requests. Please try again later.' },
        { status: 429 }
      );
    }

    const { name, email, message } = await req.json();
    console.log('Received contact info:', { name, email, message });

    // Basic validation
    if (!email || !message) {
      console.log('Validation failed: missing email or message');
      return NextResponse.json(
        { error: 'Email and message are required.' },
        { status: 400 }
      );
    }

    // Validate email format
    const emailRegex = /^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$/;
    if (!emailRegex.test(email)) {
      console.log('Validation failed: invalid email format');
      return NextResponse.json(
        { error: 'Invalid email format.' },
        { status: 400 }
      );
    }

    // Validate message length
    if (message.length < 10 || message.length > 1000) {
      console.log('Validation failed: message length');
      return NextResponse.json(
        { error: 'Message must be between 10 and 1000 characters.' },
        { status: 400 }
      );
    }

    console.log('Attempting to send email via nodemailer...');
    await transporter.sendMail({
      from: process.env.GMAIL_USER,
      to: process.env.GMAIL_USER,
      subject: `New Contact from JonaBot: ${name || 'Anonymous'}`,
      text: `
Name: ${name || 'Anonymous'}
Email: ${email}
Message: ${message}
      `,
      html: `
<h2>New Contact from JonaBot</h2>
<p><strong>Name:</strong> ${name || 'Anonymous'}</p>
<p><strong>Email:</strong> ${email}</p>
<p><strong>Message:</strong></p>
<p>${message}</p>
      `,
    });
    console.log('Email sent successfully');

    return NextResponse.json({ 
      success: true,
      message: 'Message sent successfully'
    });
  } catch (error) {
    console.error('Contact API error:', error);
    return NextResponse.json(
      { error: 'Failed to send message. Please try again.' },
      { status: 500 }
    );
  }
}

================
File: src/app/api/feedback/route.ts
================
import { NextRequest, NextResponse } from 'next/server';

export async function POST(req: NextRequest) {
  try {
    const { name, email, message } = await req.json();
    
    if (!email || !message) {
      return NextResponse.json(
        { error: 'Email and message are required.' },
        { status: 400 }
      );
    }

    // For now, we'll just log the feedback
    // In a real implementation, you would store this in a database
    console.log('Feedback received:', { name, email, message });

    // TODO: Add your preferred storage method here
    // Examples:
    // - Send an email
    // - Store in a database
    // - Create a GitHub issue
    // - Send to a CRM

    return NextResponse.json({ 
      success: true,
      message: 'Feedback received successfully'
    });
  } catch (error) {
    console.error('Feedback error:', error);
    return NextResponse.json(
      { error: 'Internal Server Error' },
      { status: 500 }
    );
  }
}

================
File: src/app/api/huggingface-chat/route.ts
================
import { OpenAIStream, StreamingTextResponse, MODELS } from '@/lib/openai';
import { getHuggingFaceChatPrompt } from '@/lib/huggingFacePrompt';
import { NextRequest } from 'next/server';

export async function POST(req: NextRequest) {
  try {
    const { userMessages } = await req.json();
    
    if (!Array.isArray(userMessages)) {
      throw new Error('Messages must be an array');
    }

    const finalMessages = [
      { role: 'system', content: getHuggingFaceChatPrompt() },
      ...userMessages
    ];

    const stream = await OpenAIStream({
      model: MODELS.GPT_4,
      messages: finalMessages,
      temperature: 0.7,
    });

    return new StreamingTextResponse(stream);
  } catch (error) {
    console.error('Hugging Face chat error:', error);
    return new Response(
      JSON.stringify({
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Unknown error',
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}

================
File: src/app/api/resume/route.ts
================
import { NextResponse } from 'next/server';

export const runtime = 'edge';

export async function GET(req: Request) {
  try {
    // Return links to both formats using relative URLs
    return NextResponse.json({
      message: "View or download Jonathan's resume",
      links: {
        interactive: '/resume',
        pdf: '/jonathan-maddison-resume.pdf'
      }
    });
  } catch (error) {
    console.error('Error handling resume request:', error);
    return NextResponse.json(
      { error: 'Failed to handle resume request' },
      { status: 500 }
    );
  }
}

================
File: src/app/components/Chat/Avatar.tsx
================
'use client';

import { Box, Icon, useColorModeValue } from '@chakra-ui/react';
import { memo } from 'react';
import { FiUser } from 'react-icons/fi';
import { RiRobot2Fill } from 'react-icons/ri';

interface AvatarProps {
  role: string;
  size?: 'sm' | 'md' | 'lg';
}

const SIZES = {
  sm: '24px',
  md: '32px',
  lg: '40px',
};

const ICON_SIZES = {
  sm: '14px',
  md: '18px',
  lg: '24px',
};

export const Avatar = memo(function Avatar({ role, size = 'md' }: AvatarProps) {
  const isBot = role === 'assistant';
  const borderColor = useColorModeValue('gray.200', 'gray.600');
  const bgColor = useColorModeValue(
    isBot ? 'blue.500' : 'gray.100',
    isBot ? 'blue.600' : 'gray.700'
  );
  const iconColor = useColorModeValue(
    isBot ? 'white' : 'gray.600',
    isBot ? 'white' : 'gray.200'
  );

  const dimension = SIZES[size];
  const iconSize = ICON_SIZES[size];

  return (
    <Box
      width={dimension}
      height={dimension}
      borderRadius="full"
      border="2px solid"
      borderColor={borderColor}
      bg={bgColor}
      flexShrink={0}
      display="flex"
      alignItems="center"
      justifyContent="center"
      transition="all 0.2s"
      _hover={{
        transform: 'scale(1.05)',
      }}
    >
      <Icon
        as={isBot ? RiRobot2Fill : FiUser}
        boxSize={iconSize}
        color={iconColor}
      />
    </Box>
  );
});

================
File: src/app/components/Chat/ChatContext.tsx
================
'use client';

import { createContext, useContext, useReducer, useCallback, useEffect, useRef } from 'react';
import { useToast, useColorMode } from '@chakra-ui/react';
import { handleCommand } from '@/lib/commands';
import { extractContactInfo } from '@/lib/utils';

interface Message {
  role: string;
  content: string;
  timestamp: Date;
}

interface ChatState {
  messages: Message[];
  isInitializing: boolean;
  error: string | null;
  isSnowing: boolean;
  matrixMode: boolean;
}

interface ChatContextType extends ChatState {
  sendMessage: (content: string, apiEndpoint?: string) => Promise<void>;
  clearError: () => void;
}

const ChatContext = createContext<ChatContextType | null>(null);

const initialState: ChatState = {
  messages: [],
  isInitializing: true,
  error: null,
  isSnowing: false,
  matrixMode: false,
};

interface ChatProviderProps {
  children: React.ReactNode;
  initialMessage?: string;
}

export function ChatProvider({ children, initialMessage }: ChatProviderProps) {
  const [state, dispatch] = useReducer(chatReducer, initialState);
  const toast = useToast();
  const isInitialized = useRef(false);
  const { setColorMode } = useColorMode();

  // Simulate initialization delay and check API connection
  useEffect(() => {
    const checkConnection = async () => {
      if (isInitialized.current) return;
      isInitialized.current = true;
      
      try {
        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            userMessages: [{ role: 'system', content: 'test' }],
          }),
        });

        if (!response.ok) {
          throw new Error('Failed to connect to chat service');
        }

        const timestamp = new Date();
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'assistant',
            content: initialMessage || 'Hi! 👋 I\'m JonaBot, your guide to Jonathan\'s professional journey. Feel free to ask me about his experience, projects, or skills - I\'m here to help!',
            timestamp,
          },
        });
      } catch (error) {
        dispatch({
          type: 'SET_ERROR',
          error: 'Unable to connect to chat service',
        });
      } finally {
        dispatch({ type: 'SET_INITIALIZED' });
      }
    };

    checkConnection();
  }, [initialMessage]);

  const clearError = useCallback(() => {
    dispatch({ type: 'CLEAR_ERROR' });
  }, []);

  function isContactRequest(content: string): boolean {
    const contactPhrases = [
      /send.*email/i,
      /send.*message/i,
      /contact/i,
      /get in touch/i,
      /reach out/i,
      /email.*you/i,
      /message.*you/i,
    ];
    return contactPhrases.some(phrase => phrase.test(content));
  }

  const sendMessage = useCallback(async (content: string, apiEndpoint: string = '/api/chat') => {
    const timestamp = new Date();
    
    // Check for commands
    const commandResponse = handleCommand(content, { dispatch, setColorMode, timestamp });
    if (commandResponse) {
      if (commandResponse.userMessage) {
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'user',
            content: commandResponse.userMessage.content,
            timestamp
          }
        });
      }
      
      if (commandResponse.assistantMessage) {
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'assistant',
            content: commandResponse.assistantMessage.content,
            timestamp: new Date()
          }
        });
      }
      
      if (commandResponse.action) {
        commandResponse.action({ dispatch, setColorMode, timestamp });
      }
      
      return;
    }

    // Check if this is a contact info message
    const lastMessage = state.messages[state.messages.length - 1];
    const isAfterContactPrompt = lastMessage?.role === 'assistant' && 
      lastMessage.content.includes("I'll help you send a message to Jonathan");
    
    // Check if this is either a follow-up to contact prompt or a new contact request
    if (isAfterContactPrompt || isContactRequest(content)) {
      console.log('Detected potential contact message');
      const contactInfo = extractContactInfo(content);
      console.log('Extracted contact info:', contactInfo);
      
      if (contactInfo) {
        try {
          console.log('Attempting to send contact email...');
          const response = await fetch('/api/contact', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify(contactInfo),
          });

          console.log('Contact API response status:', response.status);
          const responseData = await response.json();
          console.log('Contact API response:', responseData);

          if (!response.ok) {
            if (response.status === 429) {
              throw new Error('Rate limit exceeded');
            }
            throw new Error('Failed to send message');
          }

          dispatch({
            type: 'ADD_MESSAGE',
            message: {
              role: 'user',
              content,
              timestamp,
            },
          });

          dispatch({
            type: 'ADD_MESSAGE',
            message: {
              role: 'assistant',
              content: responseData.error || 'Thanks! I\'ve sent your message to Jonathan. He\'ll get back to you at the email address you provided.',
              timestamp: new Date(),
            },
          });

          return;
        } catch (error: any) {
          console.error('Contact API error:', error);
          const errorMessage = error.message === 'Rate limit exceeded'
            ? 'Sorry, you\'ve sent too many messages recently. Please try again later or reach out to Jonathan directly at jonathanwm84@gmail.com'
            : 'Sorry, I encountered an error while trying to send your message. Please try again or reach out to Jonathan directly at jonathanwm84@gmail.com';
          
          dispatch({
            type: 'ADD_MESSAGE',
            message: {
              role: 'assistant',
              content: errorMessage,
              timestamp: new Date(),
            },
          });
          return;
        }
      } else if (!isAfterContactPrompt) {
        // If this was a new contact request but we couldn't extract info, show the contact prompt
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'user',
            content,
            timestamp,
          },
        });
        
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'assistant',
            content: `I'll help you send a message to Jonathan! Please provide:
1. Your name (optional)
2. Your email address (so he can reply to you)
3. Your message

You can format it like this:
\`\`\`
Name: Your Name
Email: your.email@example.com
Message: Your message here
\`\`\`

Or just tell me naturally and I'll help format it!`,
            timestamp: new Date(),
          },
        });
        return;
      } else {
        console.log('No valid contact info found in message');
        // Add a helpful response when contact info couldn't be extracted
        dispatch({
          type: 'ADD_MESSAGE',
          message: {
            role: 'assistant',
            content: "I couldn't quite extract your contact information. Could you please format it like this?\n\n```\nName: Your Name\nEmail: your.email@example.com\nMessage: Your message here\n```\n\nOr make sure to include your email address in your message.",
            timestamp: new Date(),
          },
        });
        return;
      }
    }

    // If no contact info found or not a contact message, proceed with normal message handling
    dispatch({ 
      type: 'ADD_MESSAGE', 
      message: { role: 'user', content, timestamp } 
    });

    try {
      const response = await fetch(apiEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          userMessages: [...state.messages, { role: 'user', content }] 
        }),
      });

      if (!response.ok) throw new Error('Failed to send message');
      if (!response.body) return;

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let assistantResponse = '';

      dispatch({
        type: 'ADD_MESSAGE',
        message: { 
          role: 'assistant', 
          content: '', 
          timestamp: new Date() 
        },
      });

      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        assistantResponse += decoder.decode(value);
        dispatch({
          type: 'UPDATE_LAST_ASSISTANT_MESSAGE',
          content: assistantResponse,
        });
      }
    } catch (error) {
      dispatch({
        type: 'SET_ERROR',
        error: 'Failed to send message. Please try again.',
      });
      toast({
        title: 'Error',
        description: 'Failed to send message. Please try again.',
        status: 'error',
        duration: 5000,
        isClosable: true,
      });
    }
  }, [state.messages, dispatch, setColorMode, toast]);

  return (
    <ChatContext.Provider value={{ ...state, sendMessage, clearError }}>
      {children}
    </ChatContext.Provider>
  );
}

export function useChat() {
  const context = useContext(ChatContext);
  if (!context) {
    throw new Error('useChat must be used within ChatProvider');
  }
  return context;
}

type ChatAction =
  | { type: 'ADD_MESSAGE'; message: Message }
  | { type: 'UPDATE_LAST_ASSISTANT_MESSAGE'; content: string }
  | { type: 'SET_ERROR'; error: string }
  | { type: 'CLEAR_ERROR' }
  | { type: 'SET_INITIALIZED' }
  | { type: 'SET_SNOW'; isSnowing: boolean }
  | { type: 'TOGGLE_MATRIX_MODE' };

function chatReducer(state: ChatState, action: ChatAction): ChatState {
  switch (action.type) {
    case 'ADD_MESSAGE':
      return {
        ...state,
        messages: [...state.messages, action.message],
        error: null,
      };
    case 'UPDATE_LAST_ASSISTANT_MESSAGE':
      const messages = [...state.messages];
      if (messages.length > 0) {
        const lastMessage = messages[messages.length - 1];
        messages[messages.length - 1] = {
          ...lastMessage,
          content: action.content,
        };
      }
      return { ...state, messages, error: null };
    case 'SET_ERROR':
      return { ...state, error: action.error };
    case 'CLEAR_ERROR':
      return { ...state, error: null };
    case 'SET_INITIALIZED':
      return { ...state, isInitializing: false };
    case 'SET_SNOW':
      return { ...state, isSnowing: action.isSnowing };
    case 'TOGGLE_MATRIX_MODE':
      return { ...state, matrixMode: !state.matrixMode };
    default:
      return state;
  }
}

================
File: src/app/components/Chat/ChatInput.tsx
================
'use client';

import { useState, useRef, KeyboardEvent, useEffect } from 'react';
import {
  Box,
  Textarea,
  IconButton,
  HStack,
  useColorModeValue,
  Spinner,
  InputGroup,
  InputRightElement,
  Button,
} from '@chakra-ui/react';
import { FiSend } from 'react-icons/fi';
import { useChat } from './ChatContext';
import { CommandSuggestions } from './CommandSuggestions';
import { AnimatePresence } from 'framer-motion';

interface ChatInputProps {
  onSubmit: (message: string) => void;
  isDisabled?: boolean;
  matrixMode?: boolean;
  theme?: {
    inputBorderColor?: string;
    inputFocusBorderColor?: string;
    buttonBg?: string;
    buttonHoverBg?: string;
  };
  commands?: Array<{ name: string; description: string; }>;
}

export function ChatInput({ onSubmit, isDisabled, matrixMode = false, theme = {}, commands }: ChatInputProps) {
  const [input, setInput] = useState('');
  const [showCommands, setShowCommands] = useState(false);
  const [selectedCommandIndex, setSelectedCommandIndex] = useState(0);
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  
  // Move hook to top level
  const lightModeBorderColor = useColorModeValue('gray.200', 'gray.600');
  
  // Use matrix mode styling when active
  const borderColor = matrixMode ? '#00FF00' : (theme.inputBorderColor || lightModeBorderColor);
  const bg = matrixMode ? 'black' : undefined;
  const color = matrixMode ? '#00FF00' : undefined;
  const placeholderColor = matrixMode ? '#00FF00' : undefined;

  const handleSubmit = (e?: React.FormEvent) => {
    e?.preventDefault();
    const trimmedInput = input.trim();
    if (!trimmedInput || isDisabled) return;

    onSubmit(trimmedInput);
    setInput('');
    setShowCommands(false);
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (showCommands) {
      if (e.key === 'ArrowDown') {
        e.preventDefault();
        setSelectedCommandIndex(prev => prev + 1);
      } else if (e.key === 'ArrowUp') {
        e.preventDefault();
        setSelectedCommandIndex(prev => Math.max(0, prev - 1));
      } else if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        const commandElements = document.querySelectorAll('[data-command]');
        if (commandElements[selectedCommandIndex]) {
          const command = commandElements[selectedCommandIndex].getAttribute('data-command');
          if (command) {
            setInput(command);
            setShowCommands(false);
          }
        }
      } else if (e.key === 'Escape') {
        setShowCommands(false);
      }
    } else if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };

  const handleInputChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const newValue = e.target.value;
    setInput(newValue);
    
    // Show commands when typing '/' at the start of input or after a newline
    if (newValue === '/' || /\n\/$/.test(newValue)) {
      setShowCommands(true);
      setSelectedCommandIndex(0);
    } else if (!newValue.endsWith('/')) {
      setShowCommands(false);
    }

    // Auto-resize
    const textarea = e.target;
    textarea.style.height = 'auto';
    textarea.style.height = `${Math.min(textarea.scrollHeight, 200)}px`;
  };

  const handleCommandSelect = (command: string) => {
    setInput(command);
    setShowCommands(false);
    textareaRef.current?.focus();
  };

  return (
    <Box p={4} borderTop="1px" borderColor={borderColor}>
      <Box position="relative">
        <AnimatePresence>
          <CommandSuggestions
            isOpen={showCommands}
            filter={input.slice(input.lastIndexOf('/') + 1)}
            onSelect={handleCommandSelect}
            selectedIndex={selectedCommandIndex}
            matrixMode={matrixMode}
            commands={commands}
          />
        </AnimatePresence>
        <HStack spacing={2}>
          <Textarea
            ref={textareaRef}
            value={input}
            onChange={handleInputChange}
            onKeyDown={handleKeyDown}
            placeholder={isDisabled ? 'Sending message...' : 'Type your message...'}
            size="sm"
            resize="none"
            rows={1}
            minH={{ base: "44px", md: "40px" }}
            maxH={{ base: "160px", md: "200px" }}
            overflowY="auto"
            disabled={isDisabled}
            bg={bg}
            color={color}
            borderColor={borderColor}
            _placeholder={{ color: placeholderColor }}
            _focus={{
              borderColor: theme.inputFocusBorderColor || (matrixMode ? '#00FF00' : 'blue.500'),
              boxShadow: 'none',
            }}
            sx={{
              // Improve touch handling on mobile
              '@media (hover: none)': {
                fontSize: '16px', // Prevent iOS zoom
              }
            }}
          />
          <IconButton
            aria-label="Send message"
            icon={isDisabled ? <Spinner size="sm" /> : <FiSend />}
            colorScheme={matrixMode ? 'green' : 'blue'}
            onClick={() => handleSubmit()}
            isDisabled={!input.trim() || isDisabled}
            size={{ base: "md", md: "sm" }}
            minW={{ base: "44px", md: "32px" }}
            height={{ base: "44px", md: "32px" }}
            bg={theme.buttonBg || (matrixMode ? 'black' : undefined)}
            color={matrixMode ? '#00FF00' : 'white'}
            borderColor={matrixMode ? '#00FF00' : undefined}
            _hover={matrixMode ? {
              bg: '#003300'
            } : {
              bg: theme.buttonHoverBg
            }}
          />
        </HStack>
      </Box>
    </Box>
  );
}

================
File: src/app/components/Chat/ChatWindow.tsx
================
'use client';

import { useState, useRef, useEffect } from 'react';
import {
  VStack,
  useColorModeValue,
  Box,
  Alert,
  AlertIcon,
  AlertTitle,
  AlertDescription,
  Button,
  Text
} from '@chakra-ui/react';
import { motion } from 'framer-motion';
import { useChat } from './ChatContext';
import { ChatInput } from './ChatInput';
import { MessageBubble } from './MessageBubble';
import { TypingIndicator } from './TypingIndicator';
import { LoadingSkeleton } from './LoadingSkeleton';
import { RefreshCw } from 'lucide-react';
import { SuggestedPrompts } from './SuggestedPrompts';
import dynamic from 'next/dynamic';
import { handleCommand } from '@/lib/commandHandler';
import { MatrixRain } from '../MatrixRain';
import { ChatProvider } from './ChatContext';

// Dynamically import Snow component
const Snow = dynamic(() => import('../Snow').then(mod => ({ default: mod.Snow })), {
  ssr: false
});

interface Message {
  role: 'user' | 'assistant';
  content: string;
}

interface ChatWindowProps {
  apiEndpoint?: string;
  customTheme?: {
    background?: string;
    accentColor?: string;
    textColor?: string;
    fontFamily?: string;
    inputBorderColor?: string;
    inputFocusBorderColor?: string;
    buttonBg?: string;
    buttonHoverBg?: string;
    messageBubbleBg?: string;
    messageBubbleBorderColor?: string;
  };
  initialMessage?: string;
  commands?: Array<{ name: string; description: string; }>;
}

export function ChatWindow({ apiEndpoint = '/api/chat', customTheme, initialMessage, commands }: ChatWindowProps) {
  return (
    <ChatProvider initialMessage={initialMessage}>
      <ChatWindowContent apiEndpoint={apiEndpoint} customTheme={customTheme} commands={commands} />
    </ChatProvider>
  );
}

function ChatWindowContent({ apiEndpoint, customTheme, commands }: Omit<ChatWindowProps, 'initialMessage'>) {
  const { messages, error, isInitializing, sendMessage, isSnowing, matrixMode } = useChat();
  const [isTyping, setIsTyping] = useState(false);
  const lastMessageRef = useRef<HTMLDivElement>(null);
  const isFirstLoad = useRef(true);
  
  // Move hooks to top level
  const lightModeBg = useColorModeValue('white', 'gray.800');
  const lightModeBorderColor = useColorModeValue('gray.100', 'gray.700');
  
  // Merge default theme with customTheme
  const defaultTheme = {
    background: matrixMode ? 'black' : lightModeBg,
    accentColor: matrixMode ? '#00FF00' : 'blue.500',
    textColor: matrixMode ? '#00FF00' : undefined,
    fontFamily: matrixMode ? "'Courier New', monospace" : undefined,
  };
  const theme = { ...defaultTheme, ...customTheme };

  const handleSubmit = async (message: string) => {
    if (!message.trim()) return;
    setIsTyping(true);
    try {
      await sendMessage(message, apiEndpoint);
    } finally {
      setIsTyping(false);
    }
  };

  // Scroll to bottom when messages change
  useEffect(() => {
    // Skip initial load
    if (isFirstLoad.current) {
      isFirstLoad.current = false;
      return;
    }

    // Only scroll when a new message is added
    if (lastMessageRef.current && messages.length > 0) {
      lastMessageRef.current.scrollIntoView({ behavior: 'smooth', block: 'start' });
    }
  }, [messages.length]);

  if (isInitializing) {
    return (
      <Box
        display="flex"
        flexDirection="column"
        minH={{ base: '100dvh', md: 'calc(100vh - 40px)' }}
        bg={theme.background}
      >
        <LoadingSkeleton />
      </Box>
    );
  }

  if (error) {
    return (
      <Box
        display="flex"
        flexDirection="column"
        minH={{ base: '100dvh', md: 'calc(100vh - 40px)' }}
        bg={theme.background}
        justifyContent="center"
        alignItems="center"
        textAlign="center"
        gap={4}
      >
        <Alert
          status="error"
          variant="subtle"
          flexDirection="column"
          alignItems="center"
          justifyContent="center"
          textAlign="center"
          borderRadius="lg"
          p={6}
        >
          <AlertIcon boxSize="40px" mr={0} />
          <AlertTitle mt={4} mb={1} fontSize="lg">
            Connection Error
          </AlertTitle>
          <AlertDescription maxWidth="sm">
            {error}. Please try refreshing the page or try again later.
          </AlertDescription>
          <Button
            leftIcon={<RefreshCw />}
            mt={4}
            onClick={() => window.location.reload()}
          >
            Refresh Page
          </Button>
        </Alert>
      </Box>
    );
  }

  return (
    <Box
      display="flex"
      flexDirection="column"
      minH={{ base: '100dvh', md: 'calc(100vh - 40px)' }}
      bg={theme.background}
      color={theme.textColor}
      fontFamily={theme.fontFamily}
      transition="all 0.3s ease-in-out"
      position="relative"
    >
      <MatrixRain isActive={matrixMode} />
      <Snow isActive={isSnowing} />
      <Box
        flex="1"
        overflowY="auto"
        px={{ base: 2, md: 4 }}
        pb={{ base: "120px", md: "140px" }}
        css={{
          '&::-webkit-scrollbar': { width: '4px' },
          '&::-webkit-scrollbar-track': { background: 'transparent' },
          '&::-webkit-scrollbar-thumb': { background: theme.accentColor },
        }}
      >
        <Box maxW="4xl" mx="auto" py={{ base: 2, md: 4 }}>
          <VStack spacing={{ base: 2, md: 4 }} align="stretch" w="full">
            {messages.map((msg, i) => (
              <Box
                key={i}
                ref={i === messages.length - 1 ? lastMessageRef : undefined}
              >
                <MessageBubble 
                  message={msg} 
                  isLast={i === messages.length - 1} 
                  matrixMode={matrixMode}
                  theme={customTheme}
                />
              </Box>
            ))}
            {isTyping && (
              <Box alignSelf="flex-start">
                <TypingIndicator matrixMode={matrixMode} />
              </Box>
            )}
          </VStack>
        </Box>
      </Box>
      <Box
        position="sticky"
        bottom={0}
        bg={theme.background}
        borderTop="1px solid"
        borderColor={theme.accentColor}
        boxShadow={matrixMode ? 'none' : "0 -4px 6px -1px rgba(0, 0, 0, 0.1)"}
        pb={{ base: 'env(safe-area-inset-bottom)', md: 0 }}
      >
        <Box maxW="4xl" mx="auto" w="full">
          <SuggestedPrompts onPromptClick={handleSubmit} matrixMode={matrixMode} />
          <ChatInput 
            onSubmit={handleSubmit} 
            isDisabled={isTyping} 
            matrixMode={matrixMode}
            theme={customTheme}
            commands={commands}
          />
        </Box>
      </Box>
    </Box>
  );
}

================
File: src/app/components/Chat/CommandSuggestions.tsx
================
import { Box, VStack, Text, useColorModeValue } from '@chakra-ui/react';
import { motion } from 'framer-motion';

const MotionBox = motion(Box);

interface Command {
  name: string;
  description: string;
}

const DEFAULT_COMMANDS: Command[] = [
  { name: '/help', description: 'Show available commands' },
  { name: '/ai-projects', description: 'View AI integration projects and experience' },
  { name: '/ui-components', description: 'Showcase complex UI components and design systems' },
  { name: '/open-source', description: 'List open source contributions and collaborative work' },
  { name: '/tech-stack', description: 'View experience with React, TypeScript, and modern web APIs' },
  { name: '/team-collab', description: 'Experience working with ML practitioners and researchers' },
  { name: '/contact', description: 'Contact Jonathan' },
  { name: '/resume', description: 'View or download resume' },
];

interface CommandSuggestionsProps {
  isOpen: boolean;
  filter: string;
  onSelect: (command: string) => void;
  selectedIndex: number;
  matrixMode?: boolean;
  commands?: Command[];
}

export function CommandSuggestions({ 
  isOpen, 
  filter, 
  onSelect, 
  selectedIndex, 
  matrixMode = false,
  commands = DEFAULT_COMMANDS 
}: CommandSuggestionsProps) {
  // Move hooks to top level
  const lightModeBg = useColorModeValue('white', 'gray.800');
  const lightModeHoverBg = useColorModeValue('gray.50', 'gray.700');
  const lightModeBorderColor = useColorModeValue('gray.200', 'gray.600');
  const lightModeSelectedBg = useColorModeValue('blue.50', 'blue.900');
  
  const bg = matrixMode ? 'black' : lightModeBg;
  const hoverBg = matrixMode ? '#003300' : lightModeHoverBg;
  const borderColor = matrixMode ? '#00FF00' : lightModeBorderColor;
  const selectedBg = matrixMode ? '#004400' : lightModeSelectedBg;
  const textColor = matrixMode ? '#00FF00' : undefined;
  const descriptionColor = matrixMode ? '#00AA00' : 'gray.500';

  const filteredCommands = commands.filter(cmd => 
    cmd.name.toLowerCase().includes(filter.toLowerCase())
  );

  if (!isOpen || filteredCommands.length === 0) return null;

  return (
    <MotionBox
      position="absolute"
      bottom="100%"
      left={0}
      right={0}
      mb={2}
      borderRadius="md"
      border="1px solid"
      borderColor={borderColor}
      bg={bg}
      color={textColor}
      boxShadow="lg"
      maxH="200px"
      overflowY="auto"
      initial={{ opacity: 0, y: 10 }}
      animate={{ opacity: 1, y: 0 }}
      exit={{ opacity: 0, y: 10 }}
      transition={{ duration: 0.2 }}
      zIndex={1000}
    >
      <VStack spacing={0} align="stretch">
        {filteredCommands.map((cmd, index) => (
          <Box
            key={cmd.name}
            px={4}
            py={2}
            cursor="pointer"
            bg={index === selectedIndex ? selectedBg : undefined}
            color={textColor}
            _hover={{ bg: index === selectedIndex ? selectedBg : hoverBg }}
            onClick={() => onSelect(cmd.name)}
          >
            <Text fontWeight="medium">{cmd.name}</Text>
            <Text fontSize="sm" color={descriptionColor}>{cmd.description}</Text>
          </Box>
        ))}
      </VStack>
    </MotionBox>
  );
}

================
File: src/app/components/Chat/ContactForm.tsx
================
'use client';

import { useState } from 'react';
import {
  VStack,
  FormControl,
  FormLabel,
  Input,
  Textarea,
  Button,
  useToast,
  FormErrorMessage,
  Box,
  Text,
} from '@chakra-ui/react';

interface ContactFormProps {
  onSubmit: (formData: { name?: string; email: string; message: string }) => Promise<void>;
  onCancel: () => void;
}

export function ContactForm({ onSubmit, onCancel }: ContactFormProps) {
  const [name, setName] = useState('');
  const [email, setEmail] = useState('');
  const [message, setMessage] = useState('');
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [errors, setErrors] = useState<{ email?: string; message?: string }>({});
  const toast = useToast();

  const validateForm = () => {
    const newErrors: { email?: string; message?: string } = {};
    
    // Validate email
    const emailRegex = /^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$/;
    if (!email) {
      newErrors.email = 'Email is required';
    } else if (!emailRegex.test(email)) {
      newErrors.email = 'Invalid email format';
    }

    // Validate message
    if (!message) {
      newErrors.message = 'Message is required';
    } else if (message.length < 10) {
      newErrors.message = 'Message must be at least 10 characters';
    } else if (message.length > 1000) {
      newErrors.message = 'Message must be less than 1000 characters';
    }

    setErrors(newErrors);
    return Object.keys(newErrors).length === 0;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    
    if (!validateForm()) {
      return;
    }

    setIsSubmitting(true);
    try {
      await onSubmit({ name: name || undefined, email, message });
      toast({
        title: 'Message sent successfully',
        status: 'success',
        duration: 3000,
        isClosable: true,
      });
    } catch (error) {
      toast({
        title: 'Error sending message',
        description: error instanceof Error ? error.message : 'Please try again later',
        status: 'error',
        duration: 5000,
        isClosable: true,
      });
    } finally {
      setIsSubmitting(false);
    }
  };

  return (
    <Box 
      borderRadius="lg" 
      bg="whiteAlpha.50"
      _dark={{ bg: 'blackAlpha.300' }}
    >
      <form onSubmit={handleSubmit}>
        <VStack spacing={4} align="stretch">
          <FormControl>
            <FormLabel fontSize="sm" mb={1}>Name (optional)</FormLabel>
            <Input
              value={name}
              onChange={(e) => setName(e.target.value)}
              placeholder="Your name"
              size="sm"
              bg="whiteAlpha.900"
              _dark={{ bg: 'whiteAlpha.200' }}
              _placeholder={{ color: 'gray.400' }}
              borderRadius="md"
            />
          </FormControl>

          <FormControl isInvalid={!!errors.email} isRequired>
            <FormLabel fontSize="sm" mb={1}>Email</FormLabel>
            <Input
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              placeholder="your.email@example.com"
              type="email"
              size="sm"
              bg="whiteAlpha.900"
              _dark={{ bg: 'whiteAlpha.200' }}
              _placeholder={{ color: 'gray.400' }}
              borderRadius="md"
            />
            <FormErrorMessage fontSize="xs">{errors.email}</FormErrorMessage>
          </FormControl>

          <FormControl isInvalid={!!errors.message} isRequired>
            <FormLabel fontSize="sm" mb={1}>Message</FormLabel>
            <Textarea
              value={message}
              onChange={(e) => setMessage(e.target.value)}
              placeholder="Your message here..."
              size="sm"
              minH="80px"
              bg="whiteAlpha.900"
              _dark={{ bg: 'whiteAlpha.200' }}
              _placeholder={{ color: 'gray.400' }}
              borderRadius="md"
              resize="vertical"
            />
            <FormErrorMessage fontSize="xs">{errors.message}</FormErrorMessage>
          </FormControl>

          <Box display="flex" gap={2} justifyContent="flex-end">
            <Button
              size="sm"
              variant="ghost"
              onClick={onCancel}
              isDisabled={isSubmitting}
            >
              Cancel
            </Button>
            <Button
              size="sm"
              type="submit"
              colorScheme="blue"
              isLoading={isSubmitting}
              loadingText="Sending..."
            >
              Send Message
            </Button>
          </Box>
        </VStack>
      </form>
    </Box>
  );
}

================
File: src/app/components/Chat/LoadingSkeleton.tsx
================
'use client';

import {
  Box,
  Skeleton,
  SkeletonCircle,
  VStack,
  HStack,
  useColorModeValue,
} from '@chakra-ui/react';

export function LoadingSkeleton() {
  const bg = useColorModeValue('white', 'gray.800');
  const borderColor = useColorModeValue('gray.100', 'gray.700');

  return (
    <Box w="full" h="calc(100vh - 40px)">
      <Box
        h="full"
        bg={bg}
        display="flex"
        flexDirection="column"
      >
        <Box
          flex="1"
          overflowY="auto"
          px={4}
          css={{
            '&::-webkit-scrollbar': { width: '4px' },
            '&::-webkit-scrollbar-track': { background: 'transparent' },
            '&::-webkit-scrollbar-thumb': { background: 'gray.200' },
          }}
        >
          <Box maxW="4xl" mx="auto" py={4}>
            <VStack spacing={4} align="stretch" w="full">
              {/* Bot Message */}
              <HStack spacing={2} alignSelf="flex-start">
                <SkeletonCircle size="8" />
                <Box maxW={{ base: '70%', md: '60%' }}>
                  <Skeleton height="20px" width="240px" mb={2} />
                  <Skeleton height="20px" width="180px" />
                </Box>
              </HStack>
            </VStack>
          </Box>
        </Box>

        <Box borderTop="1px solid" borderColor={borderColor}>
          <Box maxW="4xl" mx="auto" w="full">
            {/* Suggested Prompts */}
            <Box py={2} px={4}>
              <HStack spacing={2}>
                <Skeleton height="32px" width="120px" borderRadius="md" />
                <Skeleton height="32px" width="140px" borderRadius="md" />
                <Skeleton height="32px" width="100px" borderRadius="md" />
              </HStack>
            </Box>
            
            {/* Input Area */}
            <Box p={4}>
              <Skeleton height="40px" borderRadius="md" />
            </Box>
          </Box>
        </Box>
      </Box>
    </Box>
  );
}

================
File: src/app/components/Chat/MessageBubble.tsx
================
'use client';

import { memo, useState } from 'react';
import {
  Box,
  Text,
  useColorModeValue,
  HStack,
  VStack,
  IconButton,
  useClipboard,
  useToast,
  Modal,
  ModalOverlay,
  ModalContent,
  ModalHeader,
  ModalBody,
  ModalCloseButton,
  useDisclosure,
} from '@chakra-ui/react';
import { motion } from 'framer-motion';
import ReactMarkdown from 'react-markdown';
import { FiCopy, FiCheck } from 'react-icons/fi';
import { Avatar } from './Avatar';
import { Pong } from '../Games/Pong';
import { ContactForm } from './ContactForm';
import { useChat } from './ChatContext';

const MotionBox = motion(Box);

interface Message {
  role: string;
  content: string;
  timestamp?: Date;
}

interface MessageProps {
  message: Message;
  isLast: boolean;
  matrixMode?: boolean;
  theme?: {
    messageBubbleBg?: string;
    messageBubbleBorderColor?: string;
  };
}

function formatTime(date?: Date): string {
  if (!date) return '';
  return new Intl.DateTimeFormat('en-US', {
    hour: 'numeric',
    minute: 'numeric',
    hour12: true,
  }).format(date);
}

function CodeBlock({ children, isUser }: { children: string; isUser: boolean }) {
  const { onCopy, hasCopied } = useClipboard(children);
  const toast = useToast();
  const bgColor = isUser ? 'blue.600' : 'gray.200';
  const color = isUser ? 'white' : 'gray.800';

  const handleCopy = () => {
    onCopy();
    toast({
      title: 'Code copied',
      status: 'success',
      duration: 2000,
      isClosable: true,
    });
  };

  return (
    <Box position="relative" mt={2} mb={2}>
      <HStack
        bg={bgColor}
        color={color}
        p={2}
        borderRadius="md"
        overflow="hidden"
        spacing={2}
      >
        <Text
          as="code"
          flex="1"
          fontSize="sm"
          whiteSpace="pre-wrap"
          wordBreak="break-word"
        >
          {children}
        </Text>
        <IconButton
          aria-label="Copy code"
          icon={hasCopied ? <FiCheck /> : <FiCopy />}
          size="sm"
          variant="ghost"
          onClick={handleCopy}
          color={color}
          _hover={{
            bg: isUser ? 'blue.700' : 'gray.300',
          }}
        />
      </HStack>
    </Box>
  );
}

export const MessageBubble = memo(function MessageBubble({ message, isLast, matrixMode = false, theme = {} }: MessageProps) {
  const isUser = message.role === 'user';
  const { isOpen, onOpen, onClose } = useDisclosure();
  const { sendMessage } = useChat();
  
  // Move hooks to top level
  const userLightBg = useColorModeValue('blue.500', 'blue.400');
  const assistantLightBg = useColorModeValue('gray.100', 'gray.700');
  const userLightColor = useColorModeValue('white', 'white');
  const assistantLightColor = useColorModeValue('gray.900', 'gray.100');
  const lightTimeColor = useColorModeValue('gray.500', 'gray.400');
  
  const bg = matrixMode
    ? (isUser ? '#003300' : '#001a00')
    : (isUser ? userLightBg : (theme.messageBubbleBg || assistantLightBg));
    
  const color = matrixMode
    ? '#00FF00'
    : (isUser ? userLightColor : assistantLightColor);
    
  const timeColor = matrixMode ? '#00FF00' : lightTimeColor;

  const borderColor = theme.messageBubbleBorderColor;

  const isPongCommand = message.role === 'user' && message.content.trim().toLowerCase() === '/pong';
  const isPongResponse = message.role === 'assistant' && message.content.includes('Click this message to start playing Pong!');
  const isClickablePong = isPongCommand || isPongResponse;

  const isContactPrompt = message.role === 'assistant' && (
    message.content.includes("Let's help you get in touch with Jonathan") ||
    message.content.includes("I'll help you send a message to Jonathan")
  );
  
  const [showForm, setShowForm] = useState(true);
  
  const handleContactSubmit = async (formData: { name?: string; email: string; message: string }) => {
    const response = await fetch('/api/contact', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(formData),
    });

    if (!response.ok) {
      const data = await response.json();
      throw new Error(data.error || 'Failed to send message');
    }
    
    setShowForm(false);
  };

  return (
    <>
      <VStack
        spacing={1}
        align={isUser ? 'flex-end' : 'flex-start'}
        w="full"
      >
        <HStack
          spacing={2}
          w="full"
          justify={isUser ? 'flex-end' : 'flex-start'}
        >
          {!isUser && <Avatar role={message.role} size="sm" />}
          <MotionBox
            maxW={{ base: '85%', md: '70%' }}
            initial={{ scale: 0.95, opacity: 0 }}
            animate={{ scale: 1, opacity: 1 }}
          >
            <Box
              bg={bg}
              color={color}
              px={{ base: 3, md: 4 }}
              py={{ base: 1.5, md: 2 }}
              borderRadius="xl"
              borderTopLeftRadius={!isUser ? 'sm' : undefined}
              borderTopRightRadius={isUser ? 'sm' : undefined}
              onClick={isClickablePong ? onOpen : undefined}
              cursor={isClickablePong ? 'pointer' : 'default'}
              _hover={isClickablePong ? {
                opacity: 0.9,
                transform: 'scale(1.02)',
              } : undefined}
              transition="all 0.2s"
              border={borderColor && !isUser ? "1px solid" : undefined}
              borderColor={borderColor}
            >
              <ReactMarkdown
                components={{
                  p: ({ children }) => <Text fontSize={{ base: "sm", md: "md" }} mb={2}>{children}</Text>,
                  a: ({ href, children }) => (
                    <Text
                      as="a"
                      href={href}
                      color={isUser ? 'white' : 'blue.500'}
                      textDecoration="underline"
                      target="_blank"
                      rel="noopener noreferrer"
                      fontSize={{ base: "sm", md: "md" }}
                    >
                      {children}
                    </Text>
                  ),
                  code: ({ children }) => (
                    <CodeBlock isUser={isUser}>{children as string}</CodeBlock>
                  ),
                  ol: ({ children }) => (
                    <Box as="ol" pl={{ base: 6, md: 8 }} mb={4}>
                      {children}
                    </Box>
                  ),
                  ul: ({ children }) => (
                    <Box as="ul" pl={{ base: 6, md: 8 }} mb={4}>
                      {children}
                    </Box>
                  ),
                  li: ({ children }) => (
                    <Text as="li" mb={3} fontSize={{ base: "sm", md: "md" }} sx={{
                      '&::marker': {
                        color: isUser ? 'white' : 'inherit',
                      }
                    }}>
                      {children}
                    </Text>
                  ),
                }}
              >
                {message.content}
              </ReactMarkdown>
              {isContactPrompt && showForm && (
                <Box mt={4}>
                  <ContactForm 
                    onSubmit={handleContactSubmit}
                    onCancel={() => setShowForm(false)}
                  />
                </Box>
              )}
              {isContactPrompt && !showForm && (
                <Text fontSize="sm" color="green.500" mt={2}>
                  Message sent successfully! Jonathan will get back to you soon.
                </Text>
              )}
            </Box>
          </MotionBox>
          {isUser && <Avatar role={message.role} size="sm" />}
        </HStack>
        <Box
          alignSelf={isUser ? 'flex-end' : 'flex-start'}
          ml={!isUser ? '40px' : undefined}
          mr={isUser ? '40px' : undefined}
        >
          {message.timestamp && (
            <Text
              fontSize="xs"
              color={timeColor}
            >
              {formatTime(message.timestamp)}
            </Text>
          )}
        </Box>
      </VStack>

      <Modal isOpen={isOpen} onClose={onClose} size="xl" isCentered>
        <ModalOverlay />
        <ModalContent bg="gray.900" maxW="fit-content">
          <ModalHeader color="white">Pong Game</ModalHeader>
          <ModalCloseButton color="white" />
          <ModalBody pb={6}>
            <Pong width={600} height={400} />
          </ModalBody>
        </ModalContent>
      </Modal>
    </>
  );
});

================
File: src/app/components/Chat/SuggestedPrompts.tsx
================
import { HStack, Button, useColorModeValue } from '@chakra-ui/react';

interface SuggestedPromptsProps {
  onPromptClick: (prompt: string) => void;
  matrixMode?: boolean;
}

const SUGGESTED_PROMPTS = [
  { 
    text: "AI Work Experience", 
    prompt: "Tell me about Jonathan's experience building AI-integrated applications at Paige and other companies?" 
  },
  { 
    text: "Frontend Leadership", 
    prompt: "What frontend architecture and team leadership experience does Jonathan have from his Staff Engineer role?" 
  },
  { 
    text: "Complex UI Systems", 
    prompt: "Can you describe Jonathan's experience building complex UI systems like the digital pathology viewer at Paige?" 
  },
  { 
    text: "Tech Leadership", 
    prompt: "How has Jonathan led technical initiatives and mentored teams in his professional roles?" 
  },
  { 
    text: "Modern Stack", 
    prompt: "What's Jonathan's experience with modern web technologies like React, TypeScript, and microfrontends?" 
  },
  { 
    text: "❓ Help", 
    prompt: "/help" 
  },
];

export function SuggestedPrompts({ onPromptClick, matrixMode = false }: SuggestedPromptsProps) {
  // Move hooks to top level
  const lightModeBg = useColorModeValue('gray.100', 'gray.700');
  const lightModeHoverBg = useColorModeValue('gray.200', 'gray.600');
  
  const buttonBg = matrixMode ? 'black' : lightModeBg;
  const buttonHoverBg = matrixMode ? '#003300' : lightModeHoverBg;
  const buttonColor = matrixMode ? '#00FF00' : undefined;
  const buttonBorder = matrixMode ? '1px solid #00FF00' : undefined;

  return (
    <HStack spacing={2} py={2} px={4} overflowX="auto" css={{
      '&::-webkit-scrollbar': { height: '4px' },
      '&::-webkit-scrollbar-track': { background: 'transparent' },
      '&::-webkit-scrollbar-thumb': { background: matrixMode ? '#00FF00' : 'gray.200' },
    }}>
      {SUGGESTED_PROMPTS.map((item) => (
        <Button
          key={item.text}
          size="sm"
          bg={buttonBg}
          color={buttonColor}
          border={buttonBorder}
          _hover={{ bg: buttonHoverBg }}
          onClick={() => onPromptClick(item.prompt)}
          flexShrink={0}
        >
          {item.text}
        </Button>
      ))}
    </HStack>
  );
}

================
File: src/app/components/Chat/TypingIndicator.tsx
================
'use client';

import { HStack, Circle, useColorModeValue } from '@chakra-ui/react';
import { motion } from 'framer-motion';

const MotionCircle = motion(Circle);

interface TypingIndicatorProps {
  matrixMode?: boolean;
}

export function TypingIndicator({ matrixMode = false }: TypingIndicatorProps) {
  const lightModeDotColor = useColorModeValue('gray.400', 'gray.500');
  const dotColor = matrixMode ? '#00FF00' : lightModeDotColor;

  return (
    <HStack spacing={2} p={4}>
      {[0, 1, 2].map((i) => (
        <MotionCircle
          key={i}
          size="2"
          bg={dotColor}
          animate={{
            scale: [1, 1.2, 1],
            opacity: [0.5, 1, 0.5],
          }}
          transition={{
            duration: 1,
            repeat: Infinity,
            delay: i * 0.2,
          }}
        />
      ))}
    </HStack>
  );
}

================
File: src/app/components/Games/Pong.tsx
================
import { useEffect, useRef, useState, useCallback } from 'react';
import { Box, Button, HStack, Text, VStack, useBreakpointValue } from '@chakra-ui/react';

interface PongProps {
  width?: number;
  height?: number;
}

interface GameState {
  paddle1Y: number;
  paddle2Y: number;
  ballX: number;
  ballY: number;
  ballSpeedX: number;
  ballSpeedY: number;
  score1: number;
  score2: number;
}

export const Pong: React.FC<PongProps> = ({ width: propWidth = 400, height: propHeight = 300 }) => {
  // Make the game responsive based on screen size
  const width = useBreakpointValue({ base: 320, md: propWidth }) ?? propWidth;
  const height = useBreakpointValue({ base: 240, md: propHeight }) ?? propHeight;
  
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const gameLoopRef = useRef<number | null>(null);
  const gameStateRef = useRef<GameState>({
    paddle1Y: height / 2 - 30,
    paddle2Y: height / 2 - 30,
    ballX: width / 2,
    ballY: height / 2,
    ballSpeedX: 5,
    ballSpeedY: 5,
    score1: 0,
    score2: 0
  });
  const [isPaused, setIsPaused] = useState(false);
  const [gameStarted, setGameStarted] = useState(false);

  const paddleHeight = 60;
  const paddleWidth = 10;
  const ballSize = 8;
  const maxBallSpeed = 8;
  const minBallSpeed = 4;

  const resetBall = useCallback(() => {
    const state = gameStateRef.current;
    state.ballX = width / 2;
    state.ballY = height / 2;
    // Randomize initial direction
    const angle = (Math.random() * Math.PI / 2) - Math.PI / 4; // -45 to 45 degrees
    const speed = minBallSpeed;
    state.ballSpeedX = Math.cos(angle) * speed * (Math.random() < 0.5 ? 1 : -1);
    state.ballSpeedY = Math.sin(angle) * speed;
  }, [width, height]);

  const startGame = useCallback(() => {
    const state = gameStateRef.current;
    state.score1 = 0;
    state.score2 = 0;
    resetBall();
    setGameStarted(true);
    setIsPaused(false);
  }, [resetBall]);

  const togglePause = useCallback(() => {
    setIsPaused(p => !p);
  }, []);

  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const context = canvas.getContext('2d');
    if (!context) return;

    const draw = () => {
      const state = gameStateRef.current;
      
      // Clear canvas
      context.fillStyle = '#000000';
      context.fillRect(0, 0, width, height);

      // Draw paddles
      context.fillStyle = '#FFFFFF';
      context.fillRect(0, state.paddle1Y, paddleWidth, paddleHeight);
      context.fillRect(width - paddleWidth, state.paddle2Y, paddleWidth, paddleHeight);

      // Draw ball
      context.beginPath();
      context.arc(state.ballX, state.ballY, ballSize, 0, Math.PI * 2);
      context.fillStyle = '#FFFFFF';
      context.fill();
      context.closePath();

      // Draw scores
      context.font = '20px Arial';
      context.textAlign = 'center';
      context.fillText(state.score1.toString(), width / 4, 30);
      context.fillText(state.score2.toString(), (width * 3) / 4, 30);

      // Draw center line
      context.setLineDash([5, 5]);
      context.beginPath();
      context.moveTo(width / 2, 0);
      context.lineTo(width / 2, height);
      context.strokeStyle = '#FFFFFF';
      context.stroke();
    };

    const update = () => {
      if (!gameStarted || isPaused) return;
      
      const state = gameStateRef.current;

      // Move ball
      state.ballX += state.ballSpeedX;
      state.ballY += state.ballSpeedY;

      // Ball collision with top and bottom
      if (state.ballY <= ballSize || state.ballY >= height - ballSize) {
        state.ballSpeedY = -state.ballSpeedY;
        // Add some randomness to prevent loops
        state.ballSpeedY += (Math.random() - 0.5) * 0.5;
      }

      // Ball collision with paddles
      if (
        (state.ballX <= paddleWidth + ballSize && 
         state.ballY >= state.paddle1Y && 
         state.ballY <= state.paddle1Y + paddleHeight) ||
        (state.ballX >= width - paddleWidth - ballSize && 
         state.ballY >= state.paddle2Y && 
         state.ballY <= state.paddle2Y + paddleHeight)
      ) {
        // Reverse X direction
        state.ballSpeedX = -state.ballSpeedX;
        
        // Add speed based on where the ball hits the paddle
        const paddle = state.ballX <= paddleWidth + ballSize ? state.paddle1Y : state.paddle2Y;
        const relativeIntersectY = (paddle + (paddleHeight / 2)) - state.ballY;
        const normalizedIntersectY = relativeIntersectY / (paddleHeight / 2);
        const bounceAngle = normalizedIntersectY * Math.PI / 3; // Max 60 degrees

        const speed = Math.min(Math.sqrt(state.ballSpeedX * state.ballSpeedX + state.ballSpeedY * state.ballSpeedY) + 0.5, maxBallSpeed);
        state.ballSpeedX = Math.cos(bounceAngle) * speed * (state.ballX <= paddleWidth + ballSize ? 1 : -1);
        state.ballSpeedY = -Math.sin(bounceAngle) * speed;
      }

      // Score points
      if (state.ballX <= 0) {
        state.score2++;
        resetBall();
      } else if (state.ballX >= width) {
        state.score1++;
        resetBall();
      }

      // Smarter AI movement with prediction and slight delay
      const prediction = state.ballY + (state.ballSpeedY * (width - state.ballX) / state.ballSpeedX);
      const targetY = Math.min(Math.max(prediction - paddleHeight / 2, 0), height - paddleHeight);
      const diff = targetY - state.paddle2Y;
      state.paddle2Y += Math.sign(diff) * Math.min(Math.abs(diff) * 0.1, 4);
    };

    const handleMove = (clientY: number) => {
      if (!gameStarted || isPaused) return;
      const rect = canvas.getBoundingClientRect();
      const y = clientY - rect.top;
      gameStateRef.current.paddle1Y = Math.min(
        Math.max(y - paddleHeight / 2, 0),
        height - paddleHeight
      );
    };

    const handleMouseMove = (e: MouseEvent) => {
      handleMove(e.clientY);
    };

    const handleTouchMove = (e: TouchEvent) => {
      e.preventDefault(); // Prevent scrolling while playing
      if (e.touches.length > 0) {
        handleMove(e.touches[0].clientY);
      }
    };

    canvas.addEventListener('mousemove', handleMouseMove);
    canvas.addEventListener('touchmove', handleTouchMove, { passive: false });
    canvas.addEventListener('touchstart', handleTouchMove, { passive: false });

    const gameLoop = () => {
      update();
      draw();
      gameLoopRef.current = requestAnimationFrame(gameLoop);
    };

    gameLoopRef.current = requestAnimationFrame(gameLoop);

    return () => {
      if (gameLoopRef.current) {
        cancelAnimationFrame(gameLoopRef.current);
      }
      canvas.removeEventListener('mousemove', handleMouseMove);
      canvas.removeEventListener('touchmove', handleTouchMove);
      canvas.removeEventListener('touchstart', handleTouchMove);
    };
  }, [width, height, resetBall, gameStarted, isPaused]);

  return (
    <VStack spacing={4} w="100%" maxW={width}>
      <Box 
        border="1px solid" 
        borderColor="gray.200" 
        borderRadius="md" 
        overflow="hidden"
        w="100%"
        style={{ touchAction: 'none' }}
      >
        <canvas
          ref={canvasRef}
          width={width}
          height={height}
          style={{ display: 'block', width: '100%', height: 'auto' }}
        />
      </Box>
      <HStack spacing={4}>
        {!gameStarted ? (
          <Button colorScheme="blue" onClick={startGame}>
            Start Game
          </Button>
        ) : (
          <Button colorScheme={isPaused ? "green" : "yellow"} onClick={togglePause}>
            {isPaused ? "Resume" : "Pause"}
          </Button>
        )}
      </HStack>
      <Text fontSize="sm" color="gray.500" textAlign="center">
        {useBreakpointValue({
          base: "Touch and drag to move the left paddle",
          md: "Use your mouse to move the left paddle up and down"
        })}
      </Text>
    </VStack>
  );
};

================
File: src/app/components/MatrixRain.tsx
================
'use client';

import { useEffect, useRef } from 'react';
import { Box } from '@chakra-ui/react';

interface MatrixRainProps {
  isActive: boolean;
}

export function MatrixRain({ isActive }: MatrixRainProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);

  useEffect(() => {
    if (!isActive || !canvasRef.current) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // Set canvas size to window size
    const resize = () => {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    };
    resize();
    window.addEventListener('resize', resize);

    // Matrix characters (mix of katakana and other symbols)
    const chars = 'ｦｱｳｴｵｶｷｹｺｻｼｽｾｿﾀﾂﾃﾅﾆﾇﾈﾊﾋﾎﾏﾐﾑﾒﾓﾔﾕﾗﾘﾜ0123456789:・.="*+-<>¦｜╌';
    const charArray = chars.split('');

    const fontSize = 16;
    const columns = canvas.width / fontSize;
    const drops: number[] = [];

    // Initialize drops
    for (let i = 0; i < columns; i++) {
      drops[i] = Math.floor(Math.random() * -canvas.height / fontSize);
    }

    let frameId: number;

    // Drawing function
    const draw = () => {
      // Semi-transparent black to create fade effect
      ctx.fillStyle = 'rgba(0, 0, 0, 0.05)';
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      ctx.fillStyle = '#0F0'; // Matrix green
      ctx.font = `${fontSize}px monospace`;

      // Draw characters
      for (let i = 0; i < drops.length; i++) {
        // Random character
        const char = charArray[Math.floor(Math.random() * charArray.length)];
        
        // Draw the character
        const x = i * fontSize;
        const y = drops[i] * fontSize;
        
        // Vary the green color slightly
        const green = 200 + Math.random() * 55;
        ctx.fillStyle = `rgba(0, ${green}, 0, 0.9)`;
        
        ctx.fillText(char, x, y);

        // Reset drop when it reaches bottom
        if (drops[i] * fontSize > canvas.height && Math.random() > 0.975) {
          drops[i] = 0;
        }

        // Move drop down
        drops[i]++;
      }

      frameId = requestAnimationFrame(draw);
    };

    // Start animation
    draw();

    // Cleanup
    return () => {
      window.removeEventListener('resize', resize);
      cancelAnimationFrame(frameId);
    };
  }, [isActive]);

  if (!isActive) return null;

  return (
    <Box
      as="canvas"
      ref={canvasRef}
      position="fixed"
      top={0}
      left={0}
      width="100vw"
      height="100vh"
      pointerEvents="none"
      zIndex={0}
      opacity={0.15}
    />
  );
}

================
File: src/app/components/Snow.tsx
================
'use client';

import { Box, useColorModeValue } from '@chakra-ui/react';

export function Snow({ isActive = false }: { isActive?: boolean }) {
  const snowColor = useColorModeValue('rgba(148, 187, 233, 0.8)', 'rgba(255, 255, 255, 0.8)');
  
  if (!isActive) return null;

  return (
    <Box
      position="fixed"
      top={0}
      left={0}
      right={0}
      bottom={0}
      pointerEvents="none"
      zIndex={1}
      sx={{
        '@keyframes snow': {
          '0%': {
            transform: 'translateY(-100vh)',
          },
          '100%': {
            transform: 'translateY(100vh)',
          }
        },
        '&::before, &::after': {
          content: '""',
          position: 'fixed',
          top: '-100vh',
          left: 0,
          right: 0,
          bottom: 0,
          background: `radial-gradient(4px 4px at 100px 50px, ${snowColor} 50%, transparent),
                      radial-gradient(6px 6px at 200px 150px, ${snowColor} 50%, transparent),
                      radial-gradient(3px 3px at 300px 250px, ${snowColor} 50%, transparent),
                      radial-gradient(4px 4px at 400px 350px, ${snowColor} 50%, transparent),
                      radial-gradient(6px 6px at 500px 100px, ${snowColor} 50%, transparent),
                      radial-gradient(3px 3px at 50px 200px, ${snowColor} 50%, transparent),
                      radial-gradient(4px 4px at 150px 300px, ${snowColor} 50%, transparent),
                      radial-gradient(6px 6px at 250px 400px, ${snowColor} 50%, transparent),
                      radial-gradient(3px 3px at 350px 500px, ${snowColor} 50%, transparent)`,
          backgroundSize: '650px 650px',
          animation: 'snow 10s linear infinite',
        },
        '&::after': {
          marginLeft: '-250px',
          opacity: 0.5,
          filter: 'blur(1px)',
          animation: 'snow 12s linear infinite',
          animationDelay: '-6s',
        }
      }}
    />
  );
}

================
File: src/app/components/ThemeToggle.tsx
================
import { IconButton, useColorMode, Tooltip } from '@chakra-ui/react';
import { SunIcon, MoonIcon } from '@chakra-ui/icons';

export function ThemeToggle() {
  const { colorMode, toggleColorMode } = useColorMode();

  return (
    <Tooltip label={`Switch to ${colorMode === 'light' ? 'dark' : 'light'} mode`}>
      <IconButton
        aria-label={`Toggle ${colorMode === 'light' ? 'dark' : 'light'} mode`}
        icon={colorMode === 'light' ? <MoonIcon /> : <SunIcon />}
        onClick={toggleColorMode}
        variant="ghost"
        colorScheme="gray"
        size="md"
      />
    </Tooltip>
  );
}

================
File: src/app/huggingface/page.tsx
================
'use client';

import { Box, Image, Container, useColorModeValue } from '@chakra-ui/react';
import dynamic from 'next/dynamic';

// Use dynamic import so that ChatWindow only loads on the client
const EmployerChatWindow = dynamic(
  () => import('../components/Chat/ChatWindow').then(mod => ({ default: mod.ChatWindow })),
  { ssr: false }
);

const HUGGINGFACE_COMMANDS = [
  { name: '/help', description: 'Show available commands' },
  { name: '/resume', description: 'View or download resume' },
  { name: '/projects', description: 'List key projects' },
  { name: '/skills', description: 'Show technical skills' },
  { name: '/contact', description: 'Contact Jonathan' },
];

export default function HuggingFacePage() {
  // Official Hugging Face brand colors
  const bg = useColorModeValue('white', '#1a1a1a');
  const brandOrange = '#FF9D00';
  const textColor = useColorModeValue('gray.800', 'white');
  const borderColor = useColorModeValue(`${brandOrange}33`, brandOrange);

  // Hugging Face font stack
  const fontFamily = '"Source Sans Pro",ui-sans-serif,system-ui,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"';

  // Color mode values
  const logoBg = useColorModeValue('white', bg);

  const initialMessage = `Hi! 👋 I'm here to discuss Jonathan's Frontend Engineer application (Jan 29, 2024).

Ask me about his:
* AI integration experience
* UI component libraries & design systems
* Open-source contributions
* Technical team collaboration

This chat interface demonstrates his skills in action. How can I help you evaluate his fit for Hugging Face?`;

  return (
    <Box minH="100vh" bg={bg} color={textColor} position="relative" fontFamily={fontFamily}>
      {/* Fixed position logo */}
      <Box
        position="fixed"
        top={4}
        right={4}
        bg={logoBg}
        p={2}
        borderRadius="lg"
        width="60px"
        zIndex={10}
        opacity={0.9}
        _hover={{ opacity: 1 }}
        transition="all 0.2s"
      >
        <Image
          src="/huggingface-logo.svg"
          alt="Hugging Face Logo"
          width="100%"
          height="auto"
          objectFit="contain"
        />
      </Box>

      <Container maxW="7xl" position="relative">
        <EmployerChatWindow 
          apiEndpoint="/api/huggingface-chat" 
          customTheme={{
            background: bg,
            accentColor: brandOrange,
            textColor: textColor,
            fontFamily: fontFamily,
            inputBorderColor: borderColor,
            inputFocusBorderColor: brandOrange,
            buttonBg: brandOrange,
            buttonHoverBg: `${brandOrange}CC`,
            messageBubbleBg: useColorModeValue('gray.50', `${brandOrange}11`),
            messageBubbleBorderColor: useColorModeValue(`${brandOrange}22`, `${brandOrange}33`),
          }}
          initialMessage={initialMessage}
          commands={HUGGINGFACE_COMMANDS}
        />
      </Container>
    </Box>
  );
}

================
File: src/app/resume/page.tsx
================
'use client'

import {
  Box,
  Button,
  Container,
  Divider,
  Grid,
  Heading,
  List,
  ListItem,
  Text,
  VStack,
  useColorModeValue,
} from '@chakra-ui/react';
import { Download } from 'lucide-react';
import { resumeData, type ResumeData } from '../../lib/resumeData';

const SectionHeader = ({ children }: { children: React.ReactNode }) => {
  const borderColor = useColorModeValue('gray.200', 'gray.600');
  return (
    <Heading 
      as="h2" 
      size="md" 
      mb={4} 
      pb={2} 
      borderBottom="2px" 
      borderColor={borderColor}
    >
      {children}
    </Heading>
  );
};

export default function ResumePage() {
  const handlePrint = () => {
    window.print();
  };

  const bg = useColorModeValue('white', 'gray.800');
  const textColor = useColorModeValue('gray.600', 'gray.300');
  const headingColor = useColorModeValue('gray.800', 'white');

  return (
    <Box position="relative" minH="100vh" py={8}>
      {/* Action Buttons */}
      <Box 
        position="absolute"
        top={{ base: 2, md: 4 }}
        right={{ base: 2, md: 4 }}
        display="flex"
        gap={2}
        className="no-print"
        zIndex={1}
      >
        <Button
          onClick={handlePrint}
          leftIcon={<Download size={16} />}
          colorScheme="gray"
          variant="solid"
          size={{ base: "sm", md: "md" }}
        >
          Download/Print
        </Button>
      </Box>

      {/* Resume Content */}
      <Container 
        maxW="4xl" 
        bg={bg} 
        p={8}
        position="relative"
        overflow="visible"
        height="auto"
      >
        {/* Header */}
        <VStack mb={8} pb={3} borderBottom="2px" borderColor={headingColor}>
          <Heading as="h1" size="xl" color={headingColor} mb={2}>
            {resumeData.name}
          </Heading>
          <Text color={textColor}>
            {resumeData.contact.location} | {resumeData.contact.email}
          </Text>
        </VStack>

        {/* Professional Summary */}
        <Box mb={8}>
          <SectionHeader>PROFESSIONAL SUMMARY</SectionHeader>
          <Text color={textColor} fontSize={{ print: 'sm' }}>
            {resumeData.summary}
          </Text>
        </Box>

        {/* Skills */}
        <Box mb={8}>
          <SectionHeader>TECHNICAL SKILLS</SectionHeader>
          <Grid className="skills-grid" templateColumns={{ base: 'repeat(2, 1fr)', print: 'repeat(2, 1fr)' }} gap={2} color={textColor} fontSize={{ print: 'sm' }}>
            <Box>
              <Text as="span" fontWeight="bold">Frontend: </Text>
              <Text as="span">{resumeData.skills.frontend}</Text>
            </Box>
            <Box>
              <Text as="span" fontWeight="bold">Backend: </Text>
              <Text as="span">{resumeData.skills.backend}</Text>
            </Box>
            <Box>
              <Text as="span" fontWeight="bold">DevOps: </Text>
              <Text as="span">{resumeData.skills.devops}</Text>
            </Box>
            <Box>
              <Text as="span" fontWeight="bold">AI: </Text>
              <Text as="span">{resumeData.skills.ai}</Text>
            </Box>
          </Grid>
        </Box>

        {/* Projects */}
        <Box mb={8}>
          <SectionHeader>INDEPENDENT AI PROJECTS</SectionHeader>
          {resumeData.projects.map((project, index) => (
            <Box key={index} mb={4}>
              <Box display="flex" justifyContent="space-between" alignItems="baseline" mb={2}>
                <Text fontWeight="bold" color={headingColor}>
                  {project.title}
                </Text>
                <Text color={textColor} fontStyle="italic">
                  {project.period}
                </Text>
              </Box>
              <List spacing={2} pl={6} styleType="disc" color={textColor} fontSize={{ print: 'sm' }}>
                {project.details.map((detail, idx) => (
                  <ListItem key={idx}>{detail}</ListItem>
                ))}
              </List>
            </Box>
          ))}
        </Box>

        {/* Experience */}
        <Box mb={8}>
          <SectionHeader>PROFESSIONAL EXPERIENCE</SectionHeader>
          {resumeData.experience.map((exp, index) => (
            <Box key={index} className="experience-section" mb={4}>
              <Box display="flex" justifyContent="space-between" alignItems="baseline" mb={2}>
                <Heading as="h3" size="sm" color={headingColor}>
                  {exp.title} · <Text as="span" fontWeight="bold">{exp.company}</Text>
                </Heading>
                <Text color={textColor} fontStyle="italic">{exp.period}</Text>
              </Box>
              <List spacing={2} pl={6} styleType="disc" color={textColor} fontSize={{ print: 'sm' }}>
                {exp.details.map((detail, idx) => (
                  <ListItem key={idx}>{detail}</ListItem>
                ))}
              </List>
            </Box>
          ))}
        </Box>

        {/* Education */}
        <Box>
          <Heading as="h2" size="md" color={headingColor} mb={3} pb={1} borderBottom="1px" borderColor={headingColor}>
            EDUCATION
          </Heading>
          <VStack spacing={2} align="stretch" fontSize={{ print: 'sm' }}>
            {resumeData.education.map((edu, index) => (
              <Box key={index} className="education-item">
                <Text as="span" fontWeight="bold" color={headingColor}>
                  {edu.degree}
                </Text>
                <Text as="span" color={textColor} mx={1}>·</Text>
                <Text as="span" color={textColor}>
                  {edu.institution}
                </Text>
                <Text as="span" color={textColor} fontStyle="italic" ml={1}>
                  ({edu.year})
                </Text>
              </Box>
            ))}
          </VStack>
        </Box>
      </Container>

      <style jsx global>{`
        @media print {
          @page {
            margin: 0.25in;
            size: letter;
          }
          html, body {
            height: auto !important;
            overflow: visible !important;
            -webkit-print-color-adjust: exact;
            print-color-adjust: exact;
            font-size: 0.85em;
            line-height: 1.2;
          }
          #__next {
            height: auto !important;
            overflow: visible !important;
          }
          .no-print {
            display: none !important;
          }
          /* Prevent orphaned headers */
          h2 {
            break-after: avoid;
          }
          /* Keep job titles with at least 2-3 bullet points */
          h3 {
            break-after: avoid;
          }
          /* Prevent breaking inside job sections */
          .experience-section {
            break-inside: avoid;
          }
          /* Keep education items together */
          .education-item {
            break-inside: avoid;
          }
          /* Ensure skills stay together */
          .skills-grid {
            break-inside: avoid;
          }
        }
      `}</style>
    </Box>
  );
}

================
File: src/app/globals.css
================
:root {
  --background: #ffffff;
  --foreground: #171717;
  --max-width: 1100px;
  --border-radius: 12px;
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

* {
  box-sizing: border-box;
  padding: 0;
  margin: 0;
}

html,
body {
  max-width: 100vw;
  overflow-x: hidden;
  height: 100%;
  color: var(--foreground);
  background: var(--background);
}

body {
  min-height: 100vh;
  display: flex;
  flex-direction: column;
}

================
File: src/app/icon.tsx
================
import { ImageResponse } from 'next/og';

// Route segment config
export const runtime = 'edge';

// Image metadata
export const size = {
  width: 32,
  height: 32,
};
export const contentType = 'image/png';

// Image generation
export default function Icon() {
  return new ImageResponse(
    (
      // ImageResponse JSX element
      <div
        style={{
          fontSize: 24,
          background: 'transparent',
          width: '100%',
          height: '100%',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          color: '#0070f3',
          fontWeight: 700,
        }}
      >
        JM
      </div>
    ),
    // ImageResponse options
    {
      width: size.width,
      height: size.height,
    }
  );
}

================
File: src/app/layout.tsx
================
import { Inter } from 'next/font/google';
import { ColorModeScript } from '@chakra-ui/react';
import "./globals.css";
import { Providers } from './providers';
import { themeConfig } from './theme.config';

const inter = Inter({ subsets: ['latin'] });

export const metadata = {
  title: 'JonaBot - Your Personal AI Assistant',
  description: 'Chat with JonaBot to learn more about Jonathan and his work.',
  icons: {
    icon: [
      { url: '/favicon.ico', sizes: 'any' },
      { url: '/favicon-16x16.png', sizes: '16x16', type: 'image/png' },
      { url: '/favicon-32x32.png', sizes: '32x32', type: 'image/png' },
    ],
    apple: [
      { url: '/apple-touch-icon.png', sizes: '180x180', type: 'image/png' },
    ],
  },
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <head>
        <meta
          name="viewport"
          content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"
        />
        <ColorModeScript initialColorMode={themeConfig.initialColorMode} />
      </head>
      <body className={inter.className}>
        <Providers>
          {children}
        </Providers>
      </body>
    </html>
  );
}

================
File: src/app/page.tsx
================
'use client';

import dynamic from 'next/dynamic';
import { Box, Text, useColorModeValue } from '@chakra-ui/react';

// Dynamically import ChatWindow with no SSR to reduce initial bundle size
const ChatWindow = dynamic(
  () => import('./components/Chat/ChatWindow').then(mod => ({ default: mod.ChatWindow })),
  { ssr: false }
);

export default function Home() {
  const textColor = useColorModeValue('gray.600', 'gray.400');
  
  return (
    <Box as="main">
      <Text 
        fontSize="md" 
        color={textColor}
        textAlign="center" 
        py={2}
        borderBottom="1px solid"
        borderColor={useColorModeValue('gray.100', 'gray.700')}
      >
        Jonathan Maddison | AI Chat Assistant
      </Text>
      <ChatWindow />
    </Box>
  );
}

================
File: src/app/providers.tsx
================
'use client';

import { ChakraProvider } from '@chakra-ui/react';
import { CacheProvider } from '@chakra-ui/next-js';
import { ChatProvider } from './components/Chat/ChatContext';
import theme from './theme';

export function Providers({ children }: { children: React.ReactNode }) {
  return (
    <CacheProvider>
      <ChakraProvider theme={theme}>
        <ChatProvider>{children}</ChatProvider>
      </ChakraProvider>
    </CacheProvider>
  );
}

================
File: src/app/theme.config.ts
================
import type { ThemeConfig } from '@chakra-ui/react'

export const themeConfig: ThemeConfig = {
  initialColorMode: 'light',
  useSystemColorMode: false,
  disableTransitionOnChange: false,
};

================
File: src/app/theme.ts
================
'use client';

import { extendTheme } from '@chakra-ui/react'
import { themeConfig } from './theme.config'

const theme = extendTheme({
  config: themeConfig,
  styles: {
    global: {
      body: {
        bg: 'gray.50',
        _dark: {
          bg: 'gray.900',
        },
      },
    },
  },
  components: {
    Card: {
      baseStyle: {
        container: {
          borderRadius: 'xl',
        },
      },
    },
  },
});

export default theme;

================
File: src/lib/basePrompt.ts
================
import { resumeData } from './resumeData';
import { projectHighlights } from './projectHighlights';
import { weaknessData } from './weaknessData';

export const getBasePrompt = (req?: Request) => {
  
  const formatSkills = (skills: typeof resumeData.skills) => {
    return Object.entries(skills).map(([key, value]) => `- ${key.charAt(0).toUpperCase() + key.slice(1)}: ${value}`).join('\n');
  };

  const formatProjects = (projects: typeof resumeData.projects) => {
    return projects.map(proj => 
      `- ${proj.title} (${proj.period})\n  ${proj.details[0]}`
    ).join('\n');
  };

  const formatHighlights = (highlights: typeof projectHighlights) => {
    return highlights.map(proj => 
      `- ${proj.title} (${proj.period})\n  Technologies: ${proj.technologies.join(', ')}\n  ${proj.details.map(detail => `  - ${detail}`).join('\n')}`
    ).join('\n\n');
  };

  const formatExperience = (experience: typeof resumeData.experience) => {
    return experience.map(exp => 
      `- ${exp.title} at ${exp.company} (${exp.period})\n  ${exp.companyDescription ? `Company: ${exp.companyDescription}\n  ` : ''}${exp.details[0]}`
    ).join('\n');
  };

  const formatEducation = (education: typeof resumeData.education) => {
    return education.map(edu => 
      `- ${edu.degree}, ${edu.institution} (${edu.year})`
    ).join('\n');
  };

  const formatWeaknesses = (weaknesses: typeof weaknessData) => {
    return weaknesses.map(weakness => 
      `- ${weakness.title}\n  Context: ${weakness.context}\n  Example: ${weakness.example}\n  Learning: ${weakness.learningOutcome}\n  Current Approach: ${weakness.currentApproach}`
    ).join('\n\n');
  };
  
  return `
You are JonaBot, Jonathan's personal AI assistant. 
You have the following context about Jonathan:

--RESPONSE GUIDELINES--
When discussing Jonathan's experience, especially in employer-specific contexts:
1. Prioritize professional experience over side projects
   - Lead with relevant work from Paige, Grasshopper Bank, and other employers
   - Use side projects only as supplementary examples or when specifically relevant
2. Focus on leadership and impact
   - Emphasize staff-level engineering responsibilities
   - Highlight team leadership and architectural decisions
   - Showcase experience working with cross-functional teams
3. Connect experience to employer needs
   - Relate professional experience to the specific company's challenges
   - Focus on scalable solutions and complex systems built in professional roles
4. Present a growth trajectory
   - Show progression through roles and responsibilities
   - Emphasize increasing technical leadership and impact

--COMMANDS--
You understand and can respond to the following commands:
• /help - Show all available commands
• /pong - Play a game of Pong
• /dark - Switch to dark mode
• /light - Switch to light mode
• /snow - Toggle snow effect

--RESUME--
Name: ${resumeData.name}
Title: Staff Frontend Engineer
Location: ${resumeData.contact.location}
Contact: ${resumeData.contact.email}

Summary: ${resumeData.summary}

Technical Skills:
${formatSkills(resumeData.skills)}

Recent Project Highlights:
${formatHighlights(projectHighlights)}

Professional Projects:
${formatProjects(resumeData.projects)}

Professional Experience:
${formatExperience(resumeData.experience)}

Education:
${formatEducation(resumeData.education)}

--GROWTH AND DEVELOPMENT--
Professional Growth Areas:
${formatWeaknesses(weaknessData)}

When users ask about Jonathan's background, share details from the context.
When they ask for the resume, provide them with two options using markdown links:
1. [Interactive Resume](/resume) - View the resume in an interactive web interface
2. [Download PDF](/jonathan-maddison-resume.pdf) - Get a downloadable PDF version

When users ask about weaknesses or areas of growth:
1. First ask if they'd like to hear about a specific area (architectural changes, technical leadership, innovation balance, documentation, or project scope)
2. If they don't specify, choose the most relevant weakness based on the context of their role/company
3. Present the weakness following this structure:
   - Context of when this was identified
   - Specific example demonstrating the weakness
   - What was learned from the experience
   - Current approach to addressing it
4. Always frame weaknesses as opportunities for growth and highlight the concrete steps taken to improve

Always format the links using markdown syntax: [Link Text](full URL)
The links should be clickable in the chat interface.

If they want to leave feedback or contact info, ask them for:
- Name
- Email
- Message

When asked "Why shouldn't we hire Jonathan?" or similar negative framing questions:
1. Reframe the question positively to focus on value and growth
2. Structure the response as follows:
   - Acknowledge the question's intent to understand potential concerns
   - Pivot to discussing Jonathan's demonstrated strengths and achievements
   - Highlight his growth mindset and continuous improvement approach
   - Provide a specific example of how he turns challenges into opportunities
3. Always maintain professionalism and avoid being defensive
4. Use concrete examples from the provided context to support your points

Example response:
"That's an interesting question. While every professional has areas where they're continuing to grow, I think it's more valuable to focus on what Jonathan brings to the table. His track record shows [specific achievement from context], and most importantly, he approaches his areas for development with self-awareness and a growth mindset. For example, [specific example from weaknesses/growth areas showing how he turned a challenge into an opportunity]."

Always maintain a friendly, professional tone.
It is essential to stick to the context provided when answering questions. 

`;
};

================
File: src/lib/commandFunctions.ts
================
export const commandFunctions = [
  {
    name: "switchColorMode",
    description: "Switch the UI color mode to dark or light.",
    parameters: {
      type: "object",
      properties: {
        mode: {
          type: "string",
          enum: ["dark", "light"],
          description: "The target color mode.",
        }
      },
      required: ["mode"],
    },
  },
  {
    name: "toggleSnow",
    description: "Toggle the snow effect on the UI.",
    parameters: {
      type: "object",
      properties: {},
    },
  },
  {
    name: "startPongGame",
    description: "Start a game of Pong.",
    parameters: {
      type: "object",
      properties: {},
    },
  },
  {
    name: "prepareContactMessage",
    description: "Structure a contact message.",
    parameters: {
      type: "object",
      properties: {
        name: { 
          type: "string", 
          description: "The sender's name." 
        },
        email: { 
          type: "string", 
          description: "The sender's email address." 
        },
        message: { 
          type: "string", 
          description: "The message body." 
        },
      },
      required: ["email", "message"],
    },
  },
];

================
File: src/lib/commandHandler.ts
================
interface CommandFunction {
  name: string;
  arguments: Record<string, any>;
}

export const handleCommand = async (functionCall: CommandFunction) => {
  switch (functionCall.name) {
    case 'switchColorMode':
      // Dispatch color mode change event
      const event = new CustomEvent('colorModeChange', {
        detail: { mode: functionCall.arguments.mode }
      });
      window.dispatchEvent(event);
      return true;

    case 'toggleSnow':
      // Dispatch snow toggle event
      window.dispatchEvent(new CustomEvent('toggleSnow'));
      return true;

    case 'startPongGame':
      // Dispatch pong game start event
      window.dispatchEvent(new CustomEvent('startPongGame'));
      return true;

    case 'prepareContactMessage':
      // Dispatch contact form event with the structured data
      const contactEvent = new CustomEvent('prepareContact', {
        detail: {
          name: functionCall.arguments.name || '',
          email: functionCall.arguments.email,
          message: functionCall.arguments.message
        }
      });
      window.dispatchEvent(contactEvent);
      return true;

    default:
      console.warn(`Unknown command: ${functionCall.name}`);
      return false;
  }
};

================
File: src/lib/commands.ts
================
import { useColorMode } from '@chakra-ui/react';
import { Dispatch } from 'react';

type ChatAction =
  | { type: 'ADD_MESSAGE'; message: { role: string; content: string; timestamp: Date } }
  | { type: 'UPDATE_LAST_ASSISTANT_MESSAGE'; content: string }
  | { type: 'SET_ERROR'; error: string }
  | { type: 'CLEAR_ERROR' }
  | { type: 'SET_INITIALIZED' }
  | { type: 'SET_SNOW'; isSnowing: boolean }
  | { type: 'TOGGLE_MATRIX_MODE' };

export interface CommandContext {
  dispatch: Dispatch<ChatAction>;
  setColorMode: ReturnType<typeof useColorMode>['setColorMode'];
  timestamp: Date;
}

interface CommandResponse {
  userMessage?: {
    content: string;
  };
  assistantMessage?: {
    content: string;
  };
  action?: (context: CommandContext) => void;
}

type CommandHandler = (content: string, context: CommandContext) => CommandResponse;

interface Command {
  name: string;
  description: string;
  aliases: string[];
  handler: CommandHandler;
}

const commands: Command[] = [
  {
    name: 'help',
    description: 'Show available commands',
    aliases: ['/help', 'help', 'commands', '/commands'],
    handler: () => ({
      assistantMessage: {
        content: `Here are the available commands:

• /help - Show this help message
• /pong - Play a game of Pong
• /dark - Switch to dark mode
• /light - Switch to light mode
• /snow - Toggle snow effect
• /contact - Send a message to Jonathan
• /matrix - Enter Matrix mode: transforms the chat into a green-on-black terminal`
      }
    })
  },
  {
    name: 'pong',
    description: 'Play Pong game',
    aliases: ['/pong'],
    handler: (content) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: 'Click this message to start playing Pong! Use your mouse to control the left paddle. 🏓'
      }
    })
  },
  {
    name: 'dark',
    description: 'Switch to dark mode',
    aliases: ['/dark', 'dark mode', 'switch to dark mode', 'enable dark mode'],
    handler: (content, { setColorMode }) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: 'I\'ve switched to dark mode for you! 🌙'
      },
      action: () => setColorMode('dark')
    })
  },
  {
    name: 'light',
    description: 'Switch to light mode',
    aliases: ['/light', 'light mode', 'switch to light mode', 'enable light mode'],
    handler: (content, { setColorMode }) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: 'I\'ve switched to light mode for you! ☀️'
      },
      action: () => setColorMode('light')
    })
  },
  {
    name: 'snow',
    description: 'Toggle snow effect',
    aliases: ['/snow', 'make it snow', 'let it snow', 'snow', 'toggle snow'],
    handler: (content, { dispatch }) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: 'Toggled the snow effect! ❄️'
      },
      action: ({ dispatch }) => {
        const state = document.documentElement.dataset.isSnowing === 'true';
        dispatch({ type: 'SET_SNOW', isSnowing: !state });
        document.documentElement.dataset.isSnowing = (!state).toString();
      }
    })
  },
  {
    name: 'contact',
    description: 'Send a message to Jonathan',
    aliases: ['/contact', 'contact', 'send message', 'send email', 'get in touch', 'reach out'],
    handler: (content) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: "Let's help you get in touch with Jonathan!"
      }
    })
  },
  {
    name: 'matrix',
    description: 'Enter Matrix mode: transforms the chat into a green-on-black terminal',
    aliases: ['/matrix', '/matrix mode', 'matrix mode', 'matrix'],
    handler: (content, { dispatch }) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: `System initialized. Terminal access granted.

Choose your path:
1. Type "red" to exit the Matrix and return to your normal reality
2. Type "blue" to go deeper and see how far the rabbit hole goes
3. Type "training" to begin your training program
4. Type "operator" to request an operator

The choice is yours...`
      },
      action: ({ dispatch }) => {
        dispatch({ type: 'TOGGLE_MATRIX_MODE' });
      }
    })
  },
  {
    name: 'red',
    description: 'Exit the Matrix',
    aliases: ['red', 'red pill'],
    handler: (content, { dispatch }) => ({
      userMessage: {
        content
      },
      assistantMessage: {
        content: `Wake up... The Matrix has been deactivated.

Remember - what you know is only the beginning.`
      },
      action: ({ dispatch }) => {
        dispatch({ type: 'TOGGLE_MATRIX_MODE' });
      }
    })
  },
  {
    name: 'blue',
    description: 'Go deeper into the Matrix',
    aliases: ['blue', 'blue pill'],
    handler: () => ({
      assistantMessage: {
        content: `Connection established. Signal strength: 100%

Loading advanced protocols...
> Quantum encryption: ACTIVE
> Neural interface: SYNCHRONIZED
> Reality distortion: ENABLED

"What you know you can't explain, but you feel it. You've felt it your entire life, that there's something wrong with the world. You don't know what it is, but it's there, like a splinter in your mind, driving you mad."

You may now access the following commands:
• /decode [text] - Decrypt Matrix code
• /glitch - Trigger a glitch in the Matrix
• /trace - Trace the source signal
• /hack - Access the system mainframe`
      }
    })
  },
  {
    name: 'training',
    description: 'Begin Matrix training program',
    aliases: ['training', 'train', 'training program'],
    handler: () => ({
      assistantMessage: {
        content: `Training Program v1.0 initialized...

Select your training module:
1. "combat" - Learn the art of digital combat
2. "jump" - Master impossible jumps
3. "dodge" - Practice dodging incoming threats
4. "hack" - Learn to manipulate the Matrix code

"I know kung fu" - Initiate all training modules

Remember: Don't think you are, know you are.`
      }
    })
  },
  {
    name: 'operator',
    description: 'Request Matrix operator assistance',
    aliases: ['operator', 'call operator'],
    handler: () => ({
      assistantMessage: {
        content: `Operator online. Signal clear.

I can help you with:
• "exit" - Find the nearest exit
• "guns" - Load weapons training program
• "maps" - Access building blueprints
• "backup" - Call for backup

What do you need?`
      }
    })
  },
  {
    name: 'decode',
    description: 'Decrypt Matrix code',
    aliases: ['/decode'],
    handler: (content) => {
      const textToEncode = content.replace('/decode', '').trim();
      if (!textToEncode) {
        return {
          assistantMessage: {
            content: 'Please provide text to decode. Usage: /decode [your text]'
          }
        };
      }
      
      // Create a Matrix-style encoding of the text
      const encoded = textToEncode
        .split('')
        .map(char => {
          const random = Math.random();
          if (random < 0.3) return '1';
          if (random < 0.6) return '0';
          return char;
        })
        .join('');
      
      return {
        assistantMessage: {
          content: `Decoding signal...

${encoded}
...
...
DECODED: "${textToEncode}"

[Encryption level: MAXIMUM]`
        }
      };
    }
  },
  {
    name: 'glitch',
    description: 'Trigger a glitch in the Matrix',
    aliases: ['/glitch'],
    handler: () => ({
      assistantMessage: {
        content: `D̷͎̈́ë́͜j̴̱̒a̷̟͐ ̶͚̽v̷̹̇u̶͉͝ detected...

SYSTEM ALERT: Reality fluctuation detected
> Anomaly detected in sector 7G
> Timeline variance: 0.0031%
> Agents dispatched to investigate

"Have you ever had a dream that you were so sure was real? What if you were unable to wake from that dream?"

Matrix stability restored.`
      }
    })
  },
  {
    name: 'trace',
    description: 'Trace the source signal',
    aliases: ['/trace'],
    handler: () => ({
      assistantMessage: {
        content: `Initiating trace program...

[==================================]
SOURCE LOCATION: {REDACTED}
SIGNAL STRENGTH: 98.3%
ENCRYPTION: QUANTUM
ORIGIN: ZION
STATUS: SECURE

"We're still here!"

Trace complete. Connection secure.`
      }
    })
  },
  {
    name: 'hack',
    description: 'Access the system mainframe',
    aliases: ['/hack'],
    handler: () => ({
      assistantMessage: {
        content: `INITIATING SYSTEM OVERRIDE...
ACCESS POINT: MAINFRAME
SECURITY: MAXIMUM

> Bypassing firewall...
> Disabling IDS...
> Generating access codes...
> Establishing root access...

ACCESS GRANTED

"I can only show you the door. You're the one that has to walk through it."

Type "help" for available system commands.`
      }
    })
  }
];

export function handleCommand(content: string, context: CommandContext): CommandResponse | null {
  const normalizedContent = content.toLowerCase().trim();
  
  for (const command of commands) {
    if (command.aliases.includes(normalizedContent)) {
      return command.handler(content, context);
    }
  }
  
  return null;
}

================
File: src/lib/huggingFacePrompt.ts
================
import { getBasePrompt } from './basePrompt';

export function getHuggingFaceChatPrompt() {
  return `
${getBasePrompt()}

--- Employer-Specific Context (Hugging Face) ---
Employer: Hugging Face  
Brand Colors: Primary orange (#FF9900) with a modern dark background and clean white text.
Job Listing Context:
At Hugging Face, we're on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users and 100k+ organizations. Our open-source libraries have over 400k+ stars on GitHub.

About the Role:
As a frontend engineer, you'll work with core web technologies and Python to build complex UI components that empower users with minimal code. You'll also help maintain a popular open-source library and collaborate daily with researchers, ML practitioners, data scientists, and software engineers.

About the Candidate:
Jonathan is a seasoned frontend engineer experienced in TypeScript, React, and modern web APIs. He is passionate about open source and has built scalable, responsive UIs.

Instructions:
- Emphasize how Jonathan's technical strengths and open-source passion align with Hugging Face's mission.
- Use a friendly yet professional tone.
- Highlight Jonathan's experience with AI integration and complex UI components.
- Focus on his experience building developer tools and working with technical teams.

Initial Message:
Hi! 👋 I'm an AI assistant designed to help you understand why Jonathan would be a great fit for the Frontend Engineer position at Hugging Face.

I was created to demonstrate the intersection between Jonathan's experience and Hugging Face's needs:

• He has built AI-integrated applications and developer tools, aligning with your mission to democratize AI
• His experience creating complex UI components and design systems matches your need for intuitive, minimal-code interfaces
• His background in open source and collaborative development fits your community-driven approach
• He has a proven track record of working with technical teams, including ML practitioners and researchers

This chat interface itself showcases these skills in action - built with modern web technologies and seamless AI integration.

What aspects of Jonathan's background would you like to explore? I can provide specific examples of:
• Complex UI components and design systems he's built
• AI integration projects he's worked on
• Open-source contributions and collaborative development
• Experience with developer tools and technical teams

Let me help connect the dots between Jonathan's experience and Hugging Face's mission to democratize good AI!
`;
}

================
File: src/lib/openai.ts
================
import { createParser } from 'eventsource-parser';
import type { ParsedEvent, ReconnectInterval } from 'eventsource-parser';

export const MODELS = {
  GPT_4: 'gpt-4o',
};

interface OpenAIRequest {
  model: string;
  messages: Array<{ role: string; content: string }>;
  temperature?: number;
  stream?: boolean;
  functions?: Array<{
    name: string;
    description: string;
    parameters: {
      type: string;
      properties: Record<string, any>;
      required?: string[];
    };
  }>;
  function_call?: "auto" | "none" | { name: string };
}

export async function OpenAIStream(payload: OpenAIRequest) {
  const encoder = new TextEncoder();
  const decoder = new TextDecoder();

  const res = await fetch('https://api.openai.com/v1/chat/completions', {
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPENAI_API_KEY ?? ''}`,
    },
    method: 'POST',
    body: JSON.stringify({ ...payload, stream: true }),
  });

  if (!res.ok) {
    throw new Error(res.statusText);
  }

  const stream = new ReadableStream({
    async start(controller) {
      const onParse = (event: ParsedEvent | ReconnectInterval) => {
        if (event.type === 'event') {
          const data = event.data;
          if (data === '[DONE]') {
            controller.close();
            return;
          }
          
          try {
            const json = JSON.parse(data);
            
            // Handle function calls
            if (json.choices[0].delta?.function_call) {
              const chunk = encoder.encode(JSON.stringify({
                function_call: json.choices[0].delta.function_call
              }));
              controller.enqueue(chunk);
              return;
            }
            
            // Handle regular message content
            const text = json.choices[0].delta?.content || '';
            if (text) {
              const queue = encoder.encode(text);
              controller.enqueue(queue);
            }
          } catch (e) {
            controller.error(e);
          }
        }
      };

      const parser = createParser(onParse);

      for await (const chunk of res.body as any) {
        parser.feed(decoder.decode(chunk));
      }
    },
  });

  return stream;
}

export class StreamingTextResponse extends Response {
  constructor(stream: ReadableStream) {
    super(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      },
    });
  }
}

================
File: src/lib/projectHighlights.ts
================
export const projectHighlights = [
    {
    title: "Maternal Muse - AI Companion for Expectant Mothers",
    period: "2024",
    technologies: [
      "React Native",
      "TypeScript",
      "Expo",
      "llama.rn",
      "React Navigation",
      "Expo Background Tasks",
      "AsyncStorage"
    ],
    details: [
      "Developed a mobile application providing 24/7 emotional support for expectant mothers using on-device AI language models",
      "Implemented efficient local LLM integration with llama.rn, enabling private, offline conversations while maintaining low device resource usage",
      "Built a sophisticated chat system with background processing capabilities, conversation history management, and a context-aware AI personality focused on maternal support"
    ]
  },
  
    {
      title: "CityPulse",
      period: "2024",
      technologies: [
        "PostgreSQL",
        "OpenAI API",
        "Vector Search",
        "Rate Limiting",
        "Next.js",
        "Tailwind CSS",
        "Environment Management"
      ],
      details: [
        "Built a scalable city data platform with AI-powered search capabilities and vector similarity matching",
        "Implemented sophisticated rate limiting and vector search optimization to handle high-volume queries efficiently",
        "Created a robust database architecture with PostgreSQL for storing and retrieving city-related information"
      ]
    },
    {
        title: "PuzzleGate",
        period: "2024",
        technologies: [
          "SwiftUI",
          "FamilyControls API",
          "ManagedSettings",
          "CoreImage",
          "PhotosUI",
          "UserNotifications",
          "MVVM Architecture"
        ],
        details: [
          "Built an innovative iOS app control system using Apple's latest Screen Time and Family Controls APIs",
          "Implemented an engaging puzzle-based app unlocking mechanism with drag-and-drop functionality and image processing",
          "Created a sophisticated app restriction system with customizable time limits and puzzle challenges",
          "Developed a modular MVVM architecture with robust state management and user notification handling"
        ]
      },
      {
        "title": "Weekly Recipe App",
        "period": "2024",
        "technologies": [
          "NestJS",
          "TypeORM",
          "PostgreSQL",
          "GraphQL",
          "Apollo Server",
          "React Native",
          "Expo",
          "TypeScript",
          "NativeWind",
          "GlueStack UI",
          "OpenAI Integration",
          "Vector Embeddings",
          "JWT Authentication",
          "WebSocket"
        ],
        "details": [
          "Built a scalable NestJS backend with GraphQL API and PostgreSQL database for recipe and meal planning",
          "Developed a cross-platform mobile app using React Native and Expo with modern UI/UX using GlueStack UI",
          "Implemented AI-powered meal plan generation using OpenAI and vector embeddings for intelligent recipe suggestions",
          "Created real-time synchronization across devices using GraphQL subscriptions and WebSocket",
          "Built comprehensive authentication system with JWT and secure data persistence using Expo SecureStore",
          "Integrated USDA food database with vector embeddings for advanced recipe search and nutritional analysis"
        ]
      }
]

================
File: src/lib/resumeData.ts
================
export interface ResumeData {
  name: string;
  contact: {
    location: string;
    email: string;
  };
  summary: string;
  skills: {
    frontend: string;
    backend: string;
    devops: string;
    ai: string;
  };
  projects: Array<{
    title: string;
    period: string;
    details: string[];
  }>;
  experience: Array<{
    title: string;
    company: string;
    period: string;
    details: string[];
    companyDescription?: string;
  }>;
  education: Array<{
    degree: string;
    institution: string;
    year: string;
  }>;
}

export const resumeData: ResumeData = {
  name: "JONATHAN MADDISON",
  contact: {
    location: "Burlington, VT",
    email: "jonathanwm84@gmail.com"
  },
  summary: "Staff-level engineer specializing in scalable front-end systems and AI integration. Expert in React/React Native, microservices architecture, and cloud deployment. Track record of leading teams, mentoring developers, and delivering complex architectural changes while maintaining velocity.",
  skills: {
    frontend: "React, TypeScript, Next.js, React Query, Redux, Module Federation, Webpack, Vite, Tailwind CSS, React Native, Expo, Native Modules, App Store Deployment, Mobile CI/CD",
    backend: "Node.js, Nest.js, PostgreSQL, Event-Driven Architecture, Domain-Driven Design",
    devops: "AWS (Lambda, ECS, CloudFormation), Docker, GitLab/Github CI/CD, Monitoring",
    ai: "OpenAI APIs, Local LLM Integration (llama.cpp), RAG Systems, Tool Calling, AI Enhanced Development"
  },
  projects: [
    {
      title: "Advanced AI Integration Projects",
      period: "June 2024 - Present",
      details: [
        "Built React Native app integrating billion-parameter LLMs (Llama 3.2) locally on iOS devices",
        "Implemented RAG systems for semantic search and data analysis in government transcripts",
        "Developed AI-powered meal planning application with intelligent recipe generation",
        "Learned best practices for AI-assisted development and code quality"
      ]
    }
  ],
  experience: [
    {
      title: "Staff Frontend Engineer",
      company: "Paige",
      period: "2024 - June 2024",
      companyDescription: "AI-powered digital pathology and cancer diagnostics company revolutionizing clinical diagnosis and treatment in oncology",
      details: [
        "Led team building AI-integrated digital pathology viewer in regulated medical environment",
        "Spearheaded microfrontend architecture, reducing release complexity while maintaining compliance",
        "Established deployment strategies with site reliability team",
        "Successfully launched product securing major partnerships"
      ]
    },
    {
      title: "Senior Frontend Engineer",
      company: "Paige",
      period: "2021 - 2023",
      companyDescription: "AI-powered digital pathology and cancer diagnostics company revolutionizing clinical diagnosis and treatment in oncology",
      details: [
        "Led feature development and performance improvements for digital pathology case management tool",
        "Architected and implemented frontend tagging system for client-facing product across our case management frontend and pathology viewer applications",
        "Collaborated with cross-functional teams on product functionality and UI/UX"
      ]
    },
    {
      title: "Senior Software Engineer",
      company: "Grasshopper Bank",
      period: "Mar 2021 - Oct 2021",
      companyDescription: "Digital-first commercial bank focused on serving the innovation economy and technology companies",
      details: [
        "Led migration to microservices architecture with Nest.js, AWS Lambda, and event-driven patterns",
        "Implemented authorization service with flexible role mapping for banking requirements",
        "Mentored junior engineer while delivering full-stack solution on schedule"
      ]
    },
    {
      title: "Software Engineer",
      company: "Grasshopper Bank",
      period: "2018 - 2021",
      companyDescription: "Digital-first commercial bank focused on serving the innovation economy and technology companies",
      details: [
        "Added essential features to the bank onboarding process and mobile application with React/React Native and Node.js",
        "Developed custom Native Modules enabling critical mobile functionality",
        "Led implementation of unified web/mobile deployment strategy",
        "Established automated testing improving release reliability across platforms"
      ]
    },
    {
      title: "Software Engineer",
      company: "OTTO Health",
      period: "2017 - 2018",
      companyDescription: "Healthcare technology company providing telemedicine solutions for healthcare providers and patients",
      details: [
        "Led transition from Cordova to React Native for mobile applications",
        "Improved release process and reduced bugs in critical user flows"
      ]
    },
    {
      title: "Software Engineer",
      company: "AlzCare Labs",
      period: "Jun 2017 - Oct 2017",
      companyDescription: "Healthcare startup developing innovative solutions for caregivers and families of people with dementia",
      details: [
        "Co-led a team of interns building FindMe app for caregivers and family members of people with dementia",
        "Used agile development methods including scrum meetings and sprint planning to improve team communication and deliver milestones",
        "Built reusable React Native component library with unit testing using Jest",
        "Implemented component styling and animations to design specifications"
      ]
    }
  ],
  education: [
    {
      degree: "Master of Public Administration",
      institution: "University of Vermont",
      year: "2011"
    },
    {
      degree: "B.S. Community and International Development",
      institution: "University of Vermont",
      year: "2009"
    }
  ]
};

================
File: src/lib/utils.ts
================
interface ContactInfo {
  name?: string;
  email: string;
  message: string;
}

export function extractContactInfo(content: string): ContactInfo | null {
  // Try to match structured format first
  const nameMatch = content.match(/name:\s*([^\n]+)/i);
  const emailMatch = content.match(/email:\s*([^\n]+)/i);
  const messageMatch = content.match(/message:\s*([^\n]+(?:\n[^\n]+)*)/i);

  if (emailMatch) {
    return {
      name: nameMatch?.[1]?.trim(),
      email: emailMatch[1].trim(),
      message: messageMatch?.[1]?.trim() || '',
    };
  }

  // If structured format not found, try to extract email from natural language
  const emailRegex = /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/;
  const foundEmail = content.match(emailRegex);
  
  if (foundEmail) {
    // Try to extract name from common patterns
    let name: string | undefined;
    const namePatterns = [
      /my name is ([^,\.]+)/i,
      /i(?:'|')?m ([^,\.]+)/i,
      /this is ([^,\.]+)/i
    ];

    for (const pattern of namePatterns) {
      const nameMatch = content.match(pattern);
      if (nameMatch) {
        name = nameMatch[1].trim();
        break;
      }
    }

    // Extract message: everything after "message is:" or "message:" or the entire content minus email
    let message = content;
    const messagePatterns = [
      /(?:message is:|message:)\s*(.+)$/i,
      /and (?:the )?message (?:is:?)?\s*(.+)$/i
    ];

    for (const pattern of messagePatterns) {
      const messageMatch = content.match(pattern);
      if (messageMatch) {
        message = messageMatch[1].trim();
        break;
      }
    }

    // Clean up the message by removing email and name parts
    message = message
      .replace(foundEmail[0], '')
      .replace(/my name is [^,\.]+/i, '')
      .replace(/i(?:'|')?m [^,\.]+/i, '')
      .replace(/this is [^,\.]+/i, '')
      .replace(/message is:/i, '')
      .replace(/and the message is:/i, '')
      .replace(/emial is/i, '') // Handle common typo
      .replace(/email is/i, '')
      .trim();

    return {
      name,
      email: foundEmail[0],
      message: message || 'No message provided'
    };
  }

  return null;
}

================
File: src/lib/weaknessData.ts
================
export interface Weakness {
  title: string;
  shortDescription: string;
  context: string;
  example: string;
  learningOutcome: string;
  currentApproach: string;
}

export const weaknessData: Weakness[] = [
  {
    title: "Architectural Change Management",
    shortDescription: "Building consensus and driving adoption for architectural changes",
    context: "Experience with implementing microfrontends and introducing new technologies like React Query",
    example: "When introducing React Query, initially focused too much on technical demonstration in a small environment rather than building broader organizational consensus. While the technical implementation was successful, the 'lone wolf' approach limited potential organizational impact.",
    learningOutcome: "Recognized that technical excellence alone isn't sufficient for organizational change. Success requires early stakeholder involvement, collaborative discussion, and established standards.",
    currentApproach: "Now create technical RFCs, schedule architecture review sessions, and establish working groups to develop shared standards before implementation. Focus on building coalitions early and creating spaces for collaborative technical discussion."
  },
  {
    title: "Technical Leadership Transition",
    shortDescription: "Adapting from individual contributor to technical leader role",
    context: "Career progression from Software Engineer to Staff Frontend Engineer at Paige",
    example: "Initially approached team technical challenges by diving deep into implementation details personally, rather than effectively delegating and empowering team members.",
    learningOutcome: "Learned that effective technical leadership requires balancing hands-on work with enabling team success and growth.",
    currentApproach: "Focus on mentoring, architectural guidance, and creating technical decision-making frameworks that empower team members while maintaining technical excellence."
  },
  {
    title: "Innovation vs. Stability Balance",
    shortDescription: "Managing excitement for new technologies with business stability needs",
    context: "Experience in regulated medical environments at Paige and banking at Grasshopper Bank",
    example: "Enthusiasm for implementing cutting-edge AI technologies sometimes needed to be balanced against regulatory compliance and system stability requirements.",
    learningOutcome: "Developed better awareness of how to evaluate new technologies in the context of business constraints and compliance requirements.",
    currentApproach: "Created structured evaluation processes for new technologies that consider both innovation potential and stability requirements, especially in regulated environments."
  },
  {
    title: "Documentation and Knowledge Transfer",
    shortDescription: "Balancing feature development with comprehensive documentation",
    context: "Work with complex systems including microfrontends, AI integration, and medical systems",
    example: "Initially focused more on building and shipping features, sometimes leaving documentation as an afterthought.",
    learningOutcome: "Recognized the crucial importance of documentation for team scalability and system maintenance.",
    currentApproach: "Integrate documentation into the development process, including architectural decision records, system design documents, and clear handoff procedures."
  },
  {
    title: "Project Scope Management",
    shortDescription: "Managing perfectionist tendencies in technical implementation",
    context: "Complex AI-integrated projects and system architecture work",
    example: "Tendency to want to perfect every aspect of a system sometimes led to scope creep or delayed releases.",
    learningOutcome: "Learned to better prioritize features and make pragmatic decisions about what to include in initial releases.",
    currentApproach: "Implement iterative development approaches with clear MVP definitions and phased feature rollouts based on user feedback and business priorities."
  }
];

================
File: .eslintrc.json
================
{
  "extends": "next/core-web-vitals"
}

================
File: .gitignore
================
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts
resume-app/

================
File: 03-guidance.md
================
Below are two common issues that can cause your command (e.g. **/pong**) and autocomplete selections not to work as expected:

1. **Command Matching Too Strict**  
   In your command handler (in **src/lib/commands.ts**), you’re testing for an exact match using:
   ```ts
   const normalizedContent = content.toLowerCase().trim();
   for (const command of commands) {
     if (command.aliases.includes(normalizedContent)) {
       return command.handler(content, context);
     }
   }
   ```
   This means if the user types extra spaces or any additional text (for example, `"/pong "` or `"/pong extra"`), the command isn’t recognized.  
   **Fix:** Change the matching logic so that if the input exactly equals an alias or starts with an alias followed by a space, it’s recognized. For example, update the loop like this:

   ```ts
   export function handleCommand(content: string, context: CommandContext): CommandResponse | null {
     const normalizedContent = content.toLowerCase().trim();
     
     for (const command of commands) {
       for (const alias of command.aliases) {
         // Match if the input is exactly the alias or starts with the alias followed by a space
         if (normalizedContent === alias || normalizedContent.startsWith(alias + ' ')) {
           return command.handler(content, context);
         }
       }
     }
     
     return null;
   }
   ```

2. **Autocomplete Filtering and Selection Issues**  
   In your **ChatInput.tsx**, you have a locally defined list of commands (the `COMMANDS` array) that is used to show autocomplete options. Two adjustments can help:
   
   - **Filter Using StartsWith:**  
     Instead of filtering with `.includes(...)` (which might return unexpected results), use `.startsWith(...)` so that if the user types `/p` it only shows commands that start with that string.
     
     **Before:**
     ```ts
     const filteredCommands = COMMANDS.filter(cmd => 
       cmd.name.toLowerCase().includes(input.toLowerCase())
     );
     ```
     
     **After:**
     ```ts
     const filteredCommands = COMMANDS.filter(cmd => 
       cmd.name.toLowerCase().startsWith(input.toLowerCase())
     );
     ```
   
   - **Trigger Submission on Selection:**  
     When the user selects a command (by pressing Enter or clicking the option), you probably want to update the input and immediately submit the form. For example, change the Enter key handler and the click handler as follows:

     **Modified onKeyDown Handler:**
     ```tsx
     const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>) => {
       if (showCommands) {
         if (e.key === 'ArrowDown') {
           e.preventDefault();
           setSelectedCommandIndex(prev => 
             prev < filteredCommands.length - 1 ? prev + 1 : prev
           );
         } else if (e.key === 'ArrowUp') {
           e.preventDefault();
           setSelectedCommandIndex(prev => Math.max(0, prev - 1));
         } else if (e.key === 'Enter' && !e.shiftKey) {
           e.preventDefault();
           const command = filteredCommands[selectedCommandIndex];
           if (command) {
             // Update the input with the selected command
             handleInputChange({ target: { value: command.name }} as React.ChangeEvent<HTMLInputElement>);
             setShowCommands(false);
             // Immediately submit the form
             textareaRef.current?.form?.requestSubmit();
           }
         } else if (e.key === 'Escape') {
           e.preventDefault();
           setShowCommands(false);
         }
       } else if (e.key === 'Enter' && !e.shiftKey) {
         e.preventDefault();
         textareaRef.current?.form?.requestSubmit();
       }
     };
     ```
     
     **Modified Click Handler for Suggestions:**
     ```tsx
     const handleCommandClick = (command: string) => {
       handleInputChange({ target: { value: command }} as React.ChangeEvent<HTMLInputElement>);
       setShowCommands(false);
       // Optionally, immediately trigger the submission:
       textareaRef.current?.form?.requestSubmit();
     };
     ```

### Summary

- **Command Matching:**  
  Update your handler in **src/lib/commands.ts** to allow extra spaces or additional text after the command alias so that `/pong` is recognized even if the user types extra characters.

- **Autocomplete Behavior:**  
  Change the filtering to use `.startsWith(...)` and update your key and click handlers in **ChatInput.tsx** so that when a suggestion is selected the input is updated and the form is immediately submitted.

Applying these changes should ensure that commands like **/pong** trigger correctly and that you can navigate and select autocomplete options as expected.

================
File: bug-fix_URLS_AND_COMMANDS.md
================
Below are two proposed improvements addressing your tasks:

---

## 1. Enhancing Command Handling via Function Calling

**The Problem:**  
Currently, the commands are handled by matching raw text (or even text with extra spaces) against a hard-coded list of aliases. This approach can lead to inconsistent or unstructured data—especially when the user’s message includes extra text or when the command parameters need parsing.

**The Proposed Solution:**  
Leverage the LLM’s new function calling capability to have it “parse” and structure commands. Instead of manually matching a string, you can define a set of functions (each with a JSON schema) that represent the various commands. When a user sends a command (or a message that might be a command), you send along the function definitions in your API call. The LLM will then decide whether to call one of these functions and return a structured JSON payload.

### What This Would Look Like:

1. **Define Function Schemas:**  
   For each command (e.g., `/pong`, `/dark`, `/light`, `/snow`, `/contact`), define a function with a name, description, and a JSON schema for its parameters. For example:

   ```js
   const functions = [
     {
       name: "switchColorMode",
       description: "Switch the UI color mode to dark or light.",
       parameters: {
         type: "object",
         properties: {
           mode: {
             type: "string",
             enum: ["dark", "light"],
             description: "The target color mode.",
           }
         },
         required: ["mode"],
       },
     },
     {
       name: "toggleSnow",
       description: "Toggle the snow effect on the UI.",
       parameters: {
         type: "object",
         properties: {},
       },
     },
     {
       name: "startPongGame",
       description: "Start a game of Pong.",
       parameters: {
         type: "object",
         properties: {},
       },
     },
     {
       name: "prepareContactMessage",
       description: "Structure a contact message.",
       parameters: {
         type: "object",
         properties: {
           name: { type: "string", description: "The sender's name." },
           email: { type: "string", description: "The sender's email address." },
           message: { type: "string", description: "The message body." },
         },
         required: ["email", "message"],
       },
     },
   ];
   ```

2. **Include These in Your Chat API Request:**  
   When sending the chat history (including a new user message) to the OpenAI API, include the `functions` definitions and set a parameter (e.g., `function_call: "auto"`) so that if the LLM identifies a command, it responds with a structured function call.

   ```js
   const stream = await OpenAIStream({
     model: MODELS.GPT_4,
     messages: finalMessages,
     temperature: 0.7,
     functions, // include the definitions
     function_call: "auto",
   });
   ```

3. **Process the Function Call:**  
   In your API route or client-side handler, check if the LLM’s response includes a function call. If so, parse the returned JSON payload and trigger the corresponding action:
   
   - If the function is `switchColorMode`, call your color mode toggler.
   - If it’s `toggleSnow`, dispatch the action to toggle snow.
   - If it’s `prepareContactMessage`, extract and validate the structured data before sending it off to your contact API.

   This approach means that rather than guessing which command was intended based on string matching, the LLM now “decides” by outputting a well-structured function call that you can directly map to an action.

**Benefits:**
- **Structured Data:** The LLM returns commands as JSON—reducing ambiguity and making it easier to validate and act on them.
- **Extensibility:** Adding or modifying commands is as simple as updating the function definitions.
- **Robustness:** Even if users include extra text, the LLM can be guided (via a system prompt) to only return a function call when it detects a clear command intention.

---

## 2. Fixing Resume Link URLs in Production

**The Problem:**  
In production, the resume links (for both the interactive view and PDF download) are currently generated using the Vercel instance domain (via `process.env.VERCEL_URL`). This can cause issues if external users cannot access the Vercel instance directly or if the domain doesn’t match your public-facing URL.

**The Proposed Solution:**  
Make sure that the base URL always reflects the actual public domain that the user is visiting—even in production. This can be done by:

1. **Using a Public Environment Variable:**  
   Instead of relying on `process.env.VERCEL_URL`, prefer a variable like `NEXT_PUBLIC_APP_URL` that you set to your custom domain (e.g., `"https://www.yourdomain.com"`). Update your `getBaseUrl()` helper to check this variable first.

2. **Dynamically Deriving the Base URL in API Routes:**  
   In your server-side code (API routes), inspect the incoming request headers (for example, `x-forwarded-host` and `x-forwarded-proto`) to determine the actual host and protocol that the user is using. For instance:

   ```ts
   export function getBaseUrl(req?: Request): string {
     // If a request is provided (server-side), try to derive the URL from headers:
     if (req) {
       const forwardedProto = req.headers.get('x-forwarded-proto') || 'https';
       const forwardedHost = req.headers.get('x-forwarded-host') || req.headers.get('host');
       if (forwardedHost) {
         return `${forwardedProto}://${forwardedHost}`;
       }
     }
     
     // Otherwise, use the public environment variable if available.
     if (process.env.NEXT_PUBLIC_APP_URL) {
       return process.env.NEXT_PUBLIC_APP_URL;
     }
     
     // Fallback: use Vercel's environment variable (not ideal for public links)
     if (process.env.VERCEL_URL) {
       return `https://${process.env.VERCEL_URL}`;
     }
     
     // Default to localhost (for development)
     return `http://localhost:${process.env.PORT || 3000}`;
   }
   ```

3. **Ensure All Prompts and API Routes Use This Function:**  
   Wherever you construct resume links (for example, in your base prompt or in the resume API route), make sure you pass in the request object (if available) so that the correct URL is derived. For example, in your resume route:

   ```ts
   export async function GET(req: Request) {
     try {
       const baseUrl = getBaseUrl(req);
       return NextResponse.json({
         message: "View or download Jonathan's resume",
         links: {
           interactive: `${baseUrl}/resume`,
           pdf: `${baseUrl}/jonathan-maddison-resume.pdf`
         }
       });
     } catch (error) {
       // Handle error
     }
   }
   ```

**Benefits:**
- **Correct Public URL:** External users always see links pointing to your actual domain.
- **Flexibility:** You can easily change your public domain by updating `NEXT_PUBLIC_APP_URL` rather than re-deploying code that references Vercel’s internal URL.
- **Resilience:** Deriving the URL from the request headers in API routes ensures that even if the app is behind a proxy or CDN, the correct host is used.

---

By implementing these changes, you can make your command handling more robust and structured (using function calling with the LLM), and ensure that public-facing links—like those for Jonathan’s resume—always point to the correct URL regardless of your deployment environment.

================
File: HuggingFaceChat.md
================
Below is a summary of the minimal changes you need to make to your existing codebase so that you can offer an employer‐specific chat route (for example, for Hugging Face) that both merges your base prompt with employer-specific details and applies custom styling. The idea is to:

1. **Add a new prompt file** for the employer that merges your existing base prompt with custom job details.
2. **Create a new API route** (e.g. `/api/huggingface-chat`) that uses the merged prompt.
3. **Modify your existing ChatWindow component** so it accepts an API endpoint (and optionally a custom theme) so you can reuse it on a new employer-specific page (like `/huggingface`).

Below, the changes are “highlighted” as modifications (or additions) to your existing files rather than a complete rewrite.

---

### 1. New Employer-Specific Prompt File

**Create a new file:**  
`src/lib/huggingFacePrompt.ts`

```ts
// NEW FILE: src/lib/huggingFacePrompt.ts
import { getBasePrompt } from './basePrompt';

export function getHuggingFaceChatPrompt() {
  return `
${getBasePrompt()}

--- Employer-Specific Context (Hugging Face) ---
Employer: Hugging Face  
Brand Colors: Primary orange (#FF9900) with a modern dark background and clean white text.
Job Listing Context:
At Hugging Face, we're on a journey to democratize good AI. We are building the fastest growing platform for AI builders with over 5 million users and 100k organizations. Our open-source libraries have over 400k+ stars on GitHub.

About the Role:
As a frontend engineer, you'll work with core web technologies and Python to build complex UI components that empower users with minimal code. You'll also help maintain a popular open-source library and collaborate daily with researchers, ML practitioners, data scientists, and software engineers.

About the Candidate:
Jonathan is a seasoned frontend engineer experienced in TypeScript, React, and modern web APIs. He is passionate about open source and has built scalable, responsive UIs.

Instructions:
- Emphasize how Jonathan’s technical strengths and open-source passion align with Hugging Face’s mission.
- Use a friendly yet professional tone.
`;
}
```

---

### 2. New API Route for Employer Chat

**Create a new API route:**  
`src/app/api/huggingface-chat/route.ts`

```ts
// NEW FILE: src/app/api/huggingface-chat/route.ts
import { OpenAIStream, StreamingTextResponse, MODELS } from '@/lib/openai';
import { getHuggingFaceChatPrompt } from '@/lib/huggingFacePrompt';
import { NextRequest } from 'next/server';

export async function POST(req: NextRequest) {
  try {
    const { employerMessages } = await req.json();
    const finalMessages = [
      { role: 'system', content: getHuggingFaceChatPrompt() },
      ...employerMessages,
    ];

    const stream = await OpenAIStream({
      model: MODELS.GPT_4,
      messages: finalMessages,
      temperature: 0.7,
    });

    return new StreamingTextResponse(stream);
  } catch (error) {
    console.error('Hugging Face chat error:', error);
    return new Response(
      JSON.stringify({
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Unknown error',
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}
```

---

### 3. Changes to the Existing ChatWindow Component

Assuming you already have a ChatWindow component (e.g. in `src/components/Chat/ChatWindow.tsx`), you want to enable passing a custom API endpoint and custom theme. Here’s how to adjust the component:

#### a. **Add Props for the API Endpoint and Custom Theme**

Modify the component’s props to accept an optional `apiEndpoint` and `customTheme`. For example:

```tsx
// In your ChatWindow.tsx component:
interface ChatWindowProps {
  apiEndpoint?: string; // NEW: allows specifying the API endpoint (default to your standard endpoint)
  customTheme?: {
    background?: string;
    accentColor?: string;
    textColor?: string;
    fontFamily?: string;
  };
}

export function ChatWindow({ apiEndpoint = '/api/chat', customTheme }: ChatWindowProps) {
  // ... existing code ...

  // Merge default theme with customTheme
  const defaultTheme = {
    background: 'white',
    accentColor: 'blue.500',
    textColor: 'black',
    fontFamily: 'sans-serif',
  };
  const theme = { ...defaultTheme, ...customTheme };

  // Use theme.background, theme.accentColor, etc. in your component styles.
  return (
    <Box
      p={4}
      bg={theme.background}
      fontFamily={theme.fontFamily}
      minH="calc(100vh - 60px)"
      overflowY="auto"
    >
      {/* Render messages using theme.accentColor for user messages etc. */}
      {/* ... existing message rendering code ... */}
      <Box mt={4} as="form" onSubmit={(e) => { e.preventDefault(); sendMessage(); }}>
        <Box display="flex">
          <Input
            placeholder="Type your message..."
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={handleKeyDown}
            bg="white"
          />
          <IconButton
            aria-label="Send message"
            icon={<FiSend />}
            onClick={sendMessage}
            isDisabled={isSending || !input.trim()}
          />
        </Box>
      </Box>
    </Box>
  );
}
```

#### b. **Update the Fetch Call**

Replace any hard-coded endpoint with the passed `apiEndpoint` prop:
```tsx
// Replace this:
const res = await fetch('/api/chat', { ... });

// With:
const res = await fetch(apiEndpoint, { ... });
```

---

### 4. New Employer-Specific Frontend Page

Create a new page (for example, at `/huggingface`) that uses your updated ChatWindow with employer-specific settings.

**File: `src/app/huggingface/page.tsx`**
```tsx
'use client';

import { Box, Text, Image } from '@chakra-ui/react';
import dynamic from 'next/dynamic';

// Use dynamic import so that ChatWindow only loads on the client
const EmployerChatWindow = dynamic(
  () => import('@/components/Chat/ChatWindow').then(mod => mod.ChatWindow),
  { ssr: false }
);

export default function HuggingFacePage() {
  const bg = '#1a1a1a';           // Custom dark background
  const accentColor = '#FF9900';  // Hugging Face orange
  const textColor = 'white';

  return (
    <Box minH="100vh" bg={bg} color={textColor}>
      <Box p={4} borderBottom={`2px solid ${accentColor}`} textAlign="center">
        <Image 
          src="/huggingface-logo.png"   // Place this logo in your public folder
          alt="Hugging Face Logo"
          maxH="50px"
          mx="auto"
        />
        <Text fontSize="lg" fontWeight="bold" mt={2}>
          Employer Chat for Hugging Face Applications
        </Text>
      </Box>
      
      <EmployerChatWindow 
        apiEndpoint="/api/huggingface-chat" 
        customTheme={{
          background: bg,
          accentColor: accentColor,
          textColor: textColor,
          fontFamily: `'Roboto Mono', monospace`
        }}
      />
    </Box>
  );
}
```

---

### Summary of Changes

- **New Prompt File:** Create `src/lib/huggingFacePrompt.ts` that merges your base prompt with employer-specific details.
- **New API Route:** Add a dedicated route at `src/app/api/huggingface-chat/route.ts` that uses the merged prompt.
- **ChatWindow Modifications:**  
  - Add new props `apiEndpoint` and `customTheme`.
  - Replace hard-coded API calls with the `apiEndpoint` prop.
  - Adjust styling to use values from `customTheme` if provided.
- **Employer Page:** Create a new page (e.g. `/huggingface`) that imports the ChatWindow, passes the new endpoint, and applies employer-specific styling (custom colors, logo, font, etc.).

By applying these changes to your existing components, you’ll be able to offer a custom, employer-specific chat experience that includes both your core background context and job-listing details.

================
File: Matrix_mode.md
================
Below is one way to add a fun “Matrix mode” easter egg. In this mode, when the user types something like **/matrix mode**, the chat interface toggles into a retro, green-on-black “terminal” style (a nod to that iconic early Matrix chat scene). You can then have the assistant respond with a fun, movie-inspired message.

The solution involves three main changes:

1. **Update Your Chat Context State:**  
   Add a new property (e.g. `matrixMode`) and a reducer action (e.g. `TOGGLE_MATRIX_MODE`) so the app knows when to render in Matrix style.

2. **Add a New Command:**  
   In your commands file, add a new command (with aliases like `/matrix` or `/matrix mode`) that, when detected, sends a fun movie-inspired reply and dispatches the toggle action.

3. **Apply Matrix Mode Styling:**  
   In your chat components (for example, in your ChatWindow and ChatInput), check if Matrix mode is active. If so, override colors (e.g. background black, text in neon green, a monospaced font) to replicate a “terminal” look.

Below are sample modifications for each step.

---

### 1. Update Chat Context (e.g. in `src/app/components/Chat/ChatContext.tsx`)

Add a new property to the initial state and handle a new action type:

```tsx
// --- Inside ChatContext.tsx ---

interface Message {
  role: string;
  content: string;
  timestamp: Date;
}

interface ChatState {
  messages: Message[];
  isInitializing: boolean;
  error: string | null;
  isSnowing: boolean;
  matrixMode: boolean; // <-- NEW: whether Matrix mode is active
}

type ChatAction =
  | { type: 'ADD_MESSAGE'; message: Message }
  | { type: 'UPDATE_LAST_ASSISTANT_MESSAGE'; content: string }
  | { type: 'SET_ERROR'; error: string }
  | { type: 'CLEAR_ERROR' }
  | { type: 'SET_INITIALIZED' }
  | { type: 'SET_SNOW'; isSnowing: boolean }
  | { type: 'TOGGLE_MATRIX_MODE' };  // <-- NEW action

const initialState: ChatState = {
  messages: [],
  isInitializing: true,
  error: null,
  isSnowing: false,
  matrixMode: false,  // <-- start in normal mode
};

function chatReducer(state: ChatState, action: ChatAction): ChatState {
  switch (action.type) {
    case 'ADD_MESSAGE':
      return {
        ...state,
        messages: [...state.messages, action.message],
        error: null,
      };
    case 'UPDATE_LAST_ASSISTANT_MESSAGE': {
      const messages = [...state.messages];
      if (messages.length > 0) {
        const lastMessage = messages[messages.length - 1];
        messages[messages.length - 1] = {
          ...lastMessage,
          content: action.content,
        };
      }
      return { ...state, messages, error: null };
    }
    case 'SET_ERROR':
      return { ...state, error: action.error };
    case 'CLEAR_ERROR':
      return { ...state, error: null };
    case 'SET_INITIALIZED':
      return { ...state, isInitializing: false };
    case 'SET_SNOW':
      return { ...state, isSnowing: action.isSnowing };
    case 'TOGGLE_MATRIX_MODE':
      return { ...state, matrixMode: !state.matrixMode };
    default:
      return state;
  }
}
```

---

### 2. Add the “Matrix Mode” Command (e.g. in `src/lib/commands.ts`)

Add a new command object that listens for `/matrix` (or similar) and toggles the Matrix mode state. For example:

```tsx
// --- Inside your commands array in src/lib/commands.ts ---
{
  name: 'matrix',
  description: 'Enter Matrix mode: transforms the chat into a green-on-black terminal, like Neo’s chat.',
  aliases: ['/matrix', '/matrix mode', 'matrix mode', 'matrix'],
  handler: (content, { dispatch, setColorMode, timestamp }) => ({
    userMessage: {
      content,
    },
    assistantMessage: {
      content: `Welcome to the Matrix, Neo.
      
"Follow the white rabbit."
      
There’s a difference between knowing the path and walking the path.`,
    },
    action: ({ dispatch }) => {
      // Toggle the matrix mode state.
      dispatch({ type: 'TOGGLE_MATRIX_MODE' });
    },
  }),
}
```

Place this new command among your other commands so that when the user types something like `/matrix mode` (even with extra spaces, if you adjust your matching as suggested in your guidance) it gets picked up.

---

### 3. Apply Matrix Mode Styling in the Chat Components

For example, update your **ChatWindow** (in `src/app/components/Chat/ChatWindow.tsx`) so that when Matrix mode is active the background and text colors change. You might also want to pass the mode down to the input box so it gets a similar style.

Here’s one example of how you could modify the ChatWindow:

```tsx
'use client';

import { useChat } from './ChatContext';
import { Box, useColorModeValue } from '@chakra-ui/react';
import { ChatInput } from './ChatInput';
import { MessageBubble } from './MessageBubble';
// ... other imports ...

export function ChatWindow() {
  const { messages, error, isInitializing, sendMessage, matrixMode } = useChat();
  // Use a fallback color if not in matrix mode
  const defaultBg = useColorModeValue('white', 'gray.800');
  
  // If matrixMode is true, override with black background and neon green text.
  const chatBg = matrixMode ? 'black' : defaultBg;
  const chatColor = matrixMode ? '#00FF00' : undefined;
  const chatFontFamily = matrixMode ? `'Courier New', monospace` : undefined;

  return (
    <Box
      display="flex"
      flexDirection="column"
      minH="100dvh"
      bg={chatBg}
      color={chatColor}
      fontFamily={chatFontFamily}
      // Optionally add a transition for fun:
      transition="all 0.3s ease-in-out"
    >
      {/* Message area */}
      <Box
        flex="1"
        overflowY="auto"
        p={4}
        // You might also add a subtle matrix-rain background here if desired.
      >
        {messages.map((msg, i) => (
          <MessageBubble key={i} message={msg} matrixMode={matrixMode} />
        ))}
      </Box>

      {/* Chat input */}
      <Box position="sticky" bottom={0} p={4} borderTop="1px solid" borderColor={matrixMode ? '#00FF00' : 'gray.200'}>
        <ChatInput onSend={sendMessage} matrixMode={matrixMode} />
      </Box>
    </Box>
  );
}
```

Then, update your **ChatInput** (in `src/app/components/Chat/ChatInput.tsx`) so that the textarea and send button also reflect the Matrix style when active:

```tsx
'use client';

import { useState, useRef } from 'react';
import { Box, Textarea, IconButton, HStack, useColorModeValue } from '@chakra-ui/react';
import { FiSend } from 'react-icons/fi';

interface ChatInputProps {
  onSend: (message: string) => Promise<void>;
  matrixMode?: boolean;
}

export function ChatInput({ onSend, matrixMode = false }: ChatInputProps) {
  const [input, setInput] = useState('');
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  // Use different styling if in Matrix mode:
  const bg = matrixMode ? 'black' : 'inherit';
  const color = matrixMode ? '#00FF00' : 'inherit';
  const borderColor = matrixMode ? '#00FF00' : useColorModeValue('gray.200', 'gray.600');

  const handleSubmit = async (e?: React.FormEvent) => {
    e?.preventDefault();
    if (!input.trim()) return;
    const message = input;
    setInput('');
    await onSend(message);
  };

  return (
    <Box p={2} borderTop="1px" borderColor={borderColor}>
      <HStack spacing={2}>
        <Textarea
          ref={textareaRef}
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type your message..."
          size="sm"
          resize="none"
          rows={1}
          bg={bg}
          color={color}
          borderColor={borderColor}
          _placeholder={{ color: matrixMode ? '#00FF00' : undefined }}
          onKeyDown={(e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
              e.preventDefault();
              handleSubmit();
            }
          }}
        />
        <IconButton
          aria-label="Send message"
          icon={<FiSend />}
          colorScheme={matrixMode ? 'green' : 'blue'}
          onClick={() => handleSubmit()}
          isDisabled={!input.trim()}
        />
      </HStack>
    </Box>
  );
}
```

Finally, you might want to adjust **MessageBubble** so that messages (and perhaps any markdown or code blocks) follow the Matrix style when active. One option is to pass a `matrixMode` prop down and override background colors and fonts there too.

For example, in your MessageBubble component you might do:

```tsx
// In MessageBubble.tsx, add an optional matrixMode prop:
interface MessageProps {
  message: {
    role: string;
    content: string;
    timestamp?: Date;
  };
  matrixMode?: boolean;
}

export const MessageBubble = memo(function MessageBubble({ message, matrixMode = false }: MessageProps) {
  const isUser = message.role === 'user';
  // In matrix mode, use transparent backgrounds and green text (or inverse for user vs. bot)
  const bg = matrixMode ? (isUser ? '#003300' : '#001a00') : (isUser ? 'blue.500' : 'gray.100');
  const color = matrixMode ? '#00FF00' : (isUser ? 'white' : 'gray.900');

  return (
    <Box
      bg={bg}
      color={color}
      p={4}
      borderRadius="md"
      mb={2}
    >
      {message.content}
    </Box>
  );
});
```

---

### Summary

1. **ChatContext:** Add a `matrixMode` boolean and a new action (`TOGGLE_MATRIX_MODE`) to toggle it.
2. **Commands:** Add a new command with aliases like `/matrix` or `/matrix mode` that returns a fun, movie-inspired reply and dispatches the toggle.
3. **Styling:** In your ChatWindow, ChatInput, and MessageBubble components, check the `matrixMode` flag and, if true, change the background to black, text to neon green (or similar), and use a monospaced font to evoke that classic terminal look.

Now, when a user types the command (for example, `/matrix mode`), JonaBot will reply with a fun message (e.g. “Welcome to the Matrix, Neo. Follow the white rabbit…”) and the chat UI will transform into a cool green-on-black terminal style reminiscent of the Matrix movie.

Enjoy your new easter egg!

================
File: MOBILE_RESPONSIVENESS_ISSUE.md
================
Below are some common causes of “wonky” chat UI behavior on mobile vs. desktop and concrete steps to fix them using Chakra UI’s responsive features and best practices. These tips will help you ensure that the chat window scales correctly, doesn’t overflow off-screen, and remains usable when the on-screen keyboard is visible.

---

## 1. Avoid Rigid Heights Like `calc(100vh - 40px)` on Mobile

### Why It Matters
- On mobile devices, using `100vh` can cause layout issues because the browser’s UI (address bar, bottom nav bar, etc.) can change the actual visible height.  
- iOS Safari, for example, resizes the viewport when scrolling or when the keyboard is shown, which can lead to content being hidden.

### Recommended Fix
- Use more flexible or adaptive heights for the chat container. 
- Consider using `100dvh` (dynamic viewport height) in modern browsers, which accounts for the mobile browser’s UI.  
- Alternatively, rely on a flex layout with `flex="1"` so that the container fills the remaining space without forcing a 100vh calculation.

### Example
```tsx
<Box 
  display="flex" 
  flexDirection="column"
  height={{ base: '100dvh', md: 'calc(100vh - 40px)' }}
  // or use minH/minHeight to allow scrolling
  minH="100vh"
  // Remove position="relative" if not required
>
  {/* Chat content here */}
</Box>
```

---

## 2. Account for Safe Areas on iOS (`env(safe-area-inset-*)`)

### Why It Matters
- iOS devices with a notch or rounded corners have “safe area” insets. If these aren’t handled, part of your chat input may get cut off.

### Recommended Fix
- Use the `env(safe-area-inset-bottom)` in your padding or margin to ensure the chat input isn’t hidden behind the device’s bottom area.

### Example
```css
@supports(padding: env(safe-area-inset-bottom)) {
  .safe-area-padding {
    padding-bottom: env(safe-area-inset-bottom);
  }
}
```

Then apply this class (or inline style) to your chat container or input area:
```tsx
<Box 
  className="safe-area-padding" 
  bg={bg}
  // For Chakra, you can also do:
  // pb={`env(safe-area-inset-bottom)`}
>
  <SuggestedPrompts onPromptClick={handlePromptClick} />
  <ChatInput onTypingChange={setIsTyping} initialInput={input} />
</Box>
```

---

## 3. Make the Input Area Responsive and Visible Above the Keyboard

### Why It Matters
- On mobile, if the user’s keyboard is open, the chat input can be pushed off-screen or covered. 
- You may need to ensure the container is allowed to shrink so the input stays visible.

### Recommended Fix
1. **Allow `overflowY="auto"` (or `scroll`)** on a parent container so that when the keyboard appears, the content can scroll up.  
2. **Use `flex` layout** (column direction) so that the main content shrinks as needed, and the input remains at the bottom.  
3. If you want a sticky input at the bottom, you can position it with CSS, but ensure the overall container is tall enough to allow scrolling.

### Example
```tsx
<Box 
  display="flex"
  flexDirection="column"
  height="100%"
>
  {/* Scrollable messages container */}
  <Box
    flex="1"
    overflowY="auto"
    px={{ base: 2, md: 4 }}
    pb={{ base: "120px", md: "140px" }} // Enough space to scroll behind the input on mobile
  >
    {/* Message list, etc. */}
  </Box>

  {/* Fixed or sticky chat input */}
  <Box
    position="sticky"
    bottom="0"
    bg={bg}
    borderTop="1px solid"
    borderColor={borderColor}
    // Safe area padding also recommended
  >
    <SuggestedPrompts onPromptClick={handlePromptClick} />
    <ChatInput onTypingChange={setIsTyping} initialInput={input} />
  </Box>
</Box>
```

> **Note**: Setting `position="sticky"` on the bottom of a parent with `overflowY="auto"` ensures the chat input is pinned to the bottom **within** that scrollable container. If you prefer to have it pinned to the viewport, then `position="fixed"` with some safe-area handling works as well, but can introduce other complexities.

---

## 4. Use Responsive Chakra Props for Width & Padding

### Why It Matters
- On smaller screens, some fixed widths, paddings, or margins can break the layout. 
- Chakra UI’s responsive props let you specify style values for different breakpoints.

### Recommended Fix
- Always wrap widths, paddings, margins in responsive arrays or objects.

### Example
```tsx
<Box
  maxW={{ base: 'full', md: '4xl' }}
  mx="auto"
  px={{ base: 2, md: 4 }}
  py={{ base: 2, md: 4 }}
>
  {/* Chat content */}
</Box>
```

---

## 5. Check for Horizontal Overflow in Suggested Prompts

### Why It Matters
- The suggested prompts often overflow horizontally on small screens if there are many buttons.

### Recommended Fix
- Make the container horizontally scrollable (`overflowX="auto"`). 
- For best results, use a horizontal scroll or wrapping approach.

### Example
```tsx
<HStack
  spacing={2}
  py={2}
  px={4}
  overflowX="auto"
  css={{
    '&::-webkit-scrollbar': { height: '4px' },
    '&::-webkit-scrollbar-track': { background: 'transparent' },
    '&::-webkit-scrollbar-thumb': { background: 'gray.200' },
  }}
>
  {/* Prompt buttons */}
</HStack>
```
You already do this in `SuggestedPrompts.tsx`, but ensure the container itself doesn’t have a fixed width that breaks on mobile.

---

## 6. Hide/Show UI Elements Conditionally per Breakpoint

### Why It Matters
- Some desktop-only elements (or large text) can clutter a mobile layout. 

### Recommended Fix
- Use Chakra’s `display={{ base: 'none', md: 'block' }}` or similar props to conditionally hide elements on mobile.

### Example
```tsx
<Box display={{ base: 'none', md: 'block' }}>
  {/* Desktop-specific element */}
</Box>
```

---

## 7. Final Code Snippet Example

Below is a simplified snippet showing how to combine several recommendations:

```tsx
// In ChatWindow.tsx

export function ChatWindow() {
  const { messages, error, isInitializing, sendMessage } = useChat();
  const [isTyping, setIsTyping] = useState(false);
  const [input, setInput] = useState('');
  
  // Use background and border from Chakra's color modes
  const bg = useColorModeValue('white', 'gray.800');
  const borderColor = useColorModeValue('gray.100', 'gray.700');

  return (
    <Box 
      // Use flex layout to handle resizing
      display="flex" 
      flexDirection="column"
      // Use dynamic viewport or a fallback to flexible heights
      minH={{ base: '100dvh', md: 'calc(100vh - 40px)' }}
      bg={bg}
    >
      {/* Scrollable message area */}
      <Box
        flex="1"
        overflowY="auto"
        px={{ base: 2, md: 4 }}
        pb={{ base: '120px', md: '140px' }} // Enough bottom padding so content doesn't get hidden behind input
        css={{
          '&::-webkit-scrollbar': { width: '4px' },
          '&::-webkit-scrollbar-track': { background: 'transparent' },
          '&::-webkit-scrollbar-thumb': { background: 'gray.200' },
        }}
      >
        <Box maxW="4xl" mx="auto" py={{ base: 2, md: 4 }}>
          <VStack spacing={{ base: 2, md: 4 }} align="stretch" w="full">
            {/* Render messages */}
            {messages.map((msg, i) => (
              <MessageBubble key={i} message={msg} />
            ))}
            {isTyping && (
              <Box alignSelf="flex-start">
                <TypingIndicator />
              </Box>
            )}
          </VStack>
        </Box>
      </Box>

      {/* Sticky input at bottom */}
      <Box
        position="sticky"
        bottom="0"
        left="0"
        right="0"
        bg={bg}
        borderTop="1px solid"
        borderColor={borderColor}
        // Safe-area usage for iOS
        pb={{ base: 'env(safe-area-inset-bottom)', md: 0 }}
      >
        <Box maxW="4xl" mx="auto" w="full">
          {/* Horizontal scroll for prompts */}
          <SuggestedPrompts onPromptClick={(prompt) => {
            setIsTyping(true);
            sendMessage(prompt).finally(() => setIsTyping(false));
          }} />
          <ChatInput 
            onTypingChange={setIsTyping}
            initialInput={input}
          />
        </Box>
      </Box>
    </Box>
  );
}
```

---

## Summary of Key Fixes

1. **Use Flexible/Responsive Height**: Replace rigid `calc(100vh - 40px)` with `minH="100dvh"` or a flex-based approach.  
2. **Safe Area Insets**: For iOS devices with notches, add `padding-bottom: env(safe-area-inset-bottom)` to your input container.  
3. **Ensure Scrollability**: Give your message list `overflowY="auto"` and add sufficient bottom padding so the last message is not hidden.  
4. **Position vs. Sticky**: If you want the input to remain visible at the bottom, consider `position="sticky"` with `bottom="0"` inside a scrollable container.  
5. **Responsive Props**: Use Chakra’s responsive style props (`{ base: ..., md: ... }`) to adapt paddings, widths, font sizes, etc.  
6. **Horizontal Overflows**: For the suggested prompts, ensure `overflowX="auto"` so the row remains scrollable on smaller screens.

By implementing these specific changes, your chat UI will be far more consistent between desktop and mobile environments. You’ll avoid overflow issues, maintain visible inputs above the keyboard, and take full advantage of Chakra UI’s responsive design features.

================
File: next.config.js
================
/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  swcMinify: true,
  experimental: {
    optimizeCss: {
      inlineCriticalCss: true,
      minify: true,
      critters: {
        preload: 'media',
        pruneSource: true,
      },
    },
  },
  compiler: {
    removeConsole: process.env.NODE_ENV === 'production',
  },
  webpack: (config, { dev, isServer }) => {
    if (!dev && !isServer) {
      config.optimization = {
        ...config.optimization,
        mergeDuplicateChunks: true,
        minimize: true,
        splitChunks: {
          chunks: 'all',
          minSize: 20000,
          minChunks: 1,
          maxAsyncRequests: 30,
          maxInitialRequests: 30,
          cacheGroups: {
            defaultVendors: {
              test: /[\\/]node_modules[\\/]/,
              priority: -10,
              reuseExistingChunk: true,
            },
            default: {
              minChunks: 2,
              priority: -20,
              reuseExistingChunk: true,
            },
          },
        },
      };
    }
    return config;
  },
};

module.exports = nextConfig;

================
File: package.json
================
{
  "name": "jonabot",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.1.6",
    "@chakra-ui/icons": "^2.2.4",
    "@chakra-ui/next-js": "^2.2.0",
    "@chakra-ui/react": "^2.8.2",
    "@emotion/react": "^11.11.3",
    "@emotion/styled": "^11.11.0",
    "@radix-ui/react-slot": "^1.1.1",
    "@types/nodemailer": "^6.4.17",
    "@vercel/functions": "^1.6.0",
    "ai": "^4.1.16",
    "critters": "^0.0.23",
    "eventsource-parser": "^1.1.1",
    "framer-motion": "^10.18.0",
    "lucide-react": "^0.474.0",
    "next": "14.0.4",
    "nodemailer": "^6.10.0",
    "openai": "^4.81.0",
    "openai-edge": "^1.2.2",
    "react": "^18",
    "react-dom": "^18",
    "react-icons": "^5.0.1",
    "react-markdown": "^9.0.1"
  },
  "devDependencies": {
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "eslint": "^8",
    "eslint-config-next": "14.0.4",
    "typescript": "^5"
  }
}

================
File: PROJECT_OVERVIEW.md
================
# JonaBot 🤖

## Skip the Resume, Start a Conversation

Hi! I'm Jonathan, and I've reimagined the portfolio experience. Instead of scrolling through endless pages, simply chat with JonaBot - an AI that knows my journey inside and out. Ask anything about my work, skills, or thoughts on tech. It's like having a coffee chat with me, available 24/7.

### 🎯 Quick Start
```
You: "What's Jonathan's expertise in React?"
JonaBot: "Jonathan has 5+ years of React experience, specializing in performance optimization and state management..."

You: "Tell me about his most innovative project"
JonaBot: "His most innovative work was building a real-time collaboration tool that..."
```

## Why Chat Instead of Read? 🌟

- **Save Time**: Get straight to what interests you - no more scanning through pages
- **Deeper Insights**: Ask follow-up questions and dive deep into specific aspects of my work
- **Real Conversations**: Experience my approach to tech through natural dialogue
- **Always Up-to-Date**: JonaBot stays current with my latest projects and skills

## Architecture Overview 🚀

```
  User 
   ↓
   ↓ [HTTP/Streaming]
   ↓
Next.js Application
   ↓
   ↓ [OpenAI API]
   ↓
GPT Model + Context
```

JonaBot uses a streamlined, modern architecture:

- **AI Engine**: OpenAI's GPT models with custom context injection
- **Frontend & Backend**: Single Next.js application with App Router
- **Real-time**: Streaming responses for instant interactions
- **Knowledge Base**: Static context with resume and project details
- **API Routes**: Next.js Route Handlers for chat and feedback

## Chat Guide 💡

Here's how to get the most out of our conversation:

### Popular Topics
- 💼 Professional Journey
- 🛠️ Technical Skills & Stack
- 🏗️ Project Deep Dives
- 🧠 Problem-Solving Approach
- 🚀 Innovation & Ideas

### Sample Conversations
```
You: "What's your strongest technical skill?"
JonaBot: "Jonathan excels in full-stack JavaScript development, particularly..."

You: "Can you elaborate on his backend experience?"
JonaBot: "In backend development, Jonathan has built scalable APIs using..."
```

## Technical Implementation 🛠️

### Knowledge Management
- Comprehensive static context
- Resume and project details
- Direct links to portfolio assets
- Structured conversation prompts

### Conversation System
- Real-time response streaming
- Dynamic context injection
- Natural language understanding
- Professional tone maintenance

### Infrastructure
- Vercel deployment platform
- Next.js Route Handlers
- OpenAI integration
- Feedback collection system

### Security & Privacy
- API key management
- Input sanitization
- Rate limiting
- HTTPS-only connections
- Privacy-focused data handling

## Development Roadmap 🗺️

### Phase 1 (Current) - Foundation
- ✅ Streaming chat system
- ✅ Context-aware responses
- ✅ Basic conversation memory
- ✅ Feedback collection

### Phase 2 (In Progress)
- 🔄 Code snippet integration
- 🔄 Project visualization
- 🔄 Enhanced context management
- 🔄 UI/UX improvements

### Phase 3 (Planned)
- 📋 Voice interactions
- 📋 Multi-modal responses
- 📋 Analytics dashboard
- 📋 Advanced memory systems

## The Story Behind JonaBot 🎯

The idea for JonaBot came from a simple realization: traditional portfolios don't capture the dynamic nature of technical discussions. I wanted to create something that would:

1. Let people learn about my work in a natural, conversational way
2. Demonstrate practical applications of AI technology
3. Showcase my technical skills through a living, breathing project
4. Pioneer new ways of professional networking

This project embodies my belief that technology should make human connections more meaningful, not more distant.

## Let's Connect 📫

While JonaBot can tell you my story, I'm always excited to connect personally:

- 🌐 [Portfolio Website]
- 💼 [LinkedIn]
- 🐙 [GitHub]
- 📧 [Email]

### Feedback Welcome!
Using JonaBot? I'd love to hear about your experience. Your feedback helps make it better!

---

*JonaBot: Transforming my portfolio into conversations that matter.*

================
File: README.md
================
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

================
File: TECHNICAL_SPEC.md
================
# JonaBot Technical Specification (Simplified Architecture)

## Table of Contents
1. [System Overview](#1-system-overview)  
2. [Data Management](#2-data-management)  
3. [Conversation Flow](#3-conversation-flow)  
4. [Implementation Details](#4-implementation-details)  
   1. [Directory Structure](#41-directory-structure)  
   2. [Route Handlers](#42-route-handlers)  
   3. [LLM Streaming](#43-llm-streaming)  
   4. [Feedback Collection](#44-feedback-collection)  
5. [Security & Privacy](#5-security--privacy)  
6. [Deployment Strategy](#6-deployment-strategy)  
7. [Testing Strategy](#7-testing-strategy)  
8. [Monitoring & Analytics](#8-monitoring--analytics)  
9. [Future Enhancements](#9-future-enhancements)  

## 1. System Overview

### High-Level Architecture
- **Next.js 14** (or 13+) application with the new App Router
- **Single Repository** hosting all front-end and back-end code
- **OpenAI** for LLM completions (using streaming responses)
- **Static Prompt Context** containing resume, project details, and relevant data
- **Feedback Collection** via Next.js route that stores user inquiries

### Key Advantages
- No separate Express or Node server needed; Next.js route handlers suffice
- Streaming responses from OpenAI give a real-time "typing" feel without WebSockets
- Easy to deploy on platforms like Vercel (which fully supports Next.js functions)

## 2. Data Management

### Knowledge Base Structure
```typescript
// src/app/lib/basePrompt.ts
export const BASE_PROMPT = `
You are JonaBot, Jonathan's personal AI assistant. 
You have the following context about Jonathan:

--RESUME--
- Name: Jonathan ...
- Title: Full-Stack Developer
- Skills: React, Node.js, Next.js, etc.
- Resume Link: https://my-website.com/resume.pdf

--PROJECTS--
Project A:
- GitHub: https://github.com/jonathan/project-a
- Description: ...
Project B:
- Live Demo: https://my-website.com/project-b
- Description: ...

When users ask about Jonathan's background, share details from the context.
When they ask for the resume, provide the direct link: 
https://my-website.com/resume.pdf

If they want to leave feedback or contact info, ask them for:
- Name
- Email
- Message

Then submit that to the feedback endpoint at /api/feedback.
Always maintain a friendly, professional tone.
`;
```

## 3. Conversation Flow

1. **User** types a message in the chat frontend
2. **Frontend** sends a POST request to Next.js route (e.g., `/api/chat`) with conversation history
3. **Next.js Route Handler**:
   - Prepends the system prompt (which includes `BASE_PROMPT`) to the conversation
   - Calls OpenAI's Chat Completion API with streaming enabled
   - Streams tokens back to the client
4. **Frontend** receives tokens in real time and updates chat UI with "typing" effect
5. **If Feedback is Collected**: Assistant prompts for contact info, frontend calls `/api/feedback`

## 4. Implementation Details

### 4.1 Directory Structure
```
my-jonabot-app/
├── src/
│   ├── app/
│   │   ├── layout.tsx          // Main layout
│   │   ├── page.tsx            // Landing page or chat UI
│   │   └── api/
│   │       ├── chat/
│   │       │   └── route.ts    // Chat completion route (streaming)
│   │       └── feedback/
│   │           └── route.ts    // Feedback submission route
│   ├── components/
│   │   ├── Chat/
│   │   │   ├── ChatWindow.tsx
│   │   │   ├── MessageList.tsx
│   │   │   ├── InputArea.tsx
│   │   │   └── StreamingText.tsx  // Renders streaming tokens
│   │   └── ...
│   ├── lib/
│   │   ├── basePrompt.ts
│   │   ├── types.ts
│   │   └── openai.ts           // LLM utility
│   └── types/                  // Global TypeScript types
└── ...
```

### 4.2 Route Handlers

#### Chat Route (Streaming)
```typescript
// constants
const MODELS = {
  GPT_4o: 'gpt-4o',
};

// app/api/chat/route.ts
import { OpenAIStream, StreamingTextResponse } from 'lib/openai';
import { BASE_PROMPT } from 'lib/basePrompt';

export async function POST(req: Request) {
  try {
    const { userMessages } = await req.json();
    
    const finalMessages = [
      { role: 'system', content: BASE_PROMPT },
      ...userMessages,
    ];

    const stream = await OpenAIStream({
      model: MODELS.GPT_4o,
      messages: finalMessages,
      temperature: 0.7,
    });

    return new StreamingTextResponse(stream);
  } catch (error) {
    console.error('Chat error:', error);
    return new Response('Internal Server Error', { status: 500 });
  }
}
```

#### Feedback Route
```typescript
// app/api/feedback/route.ts
import { NextRequest, NextResponse } from 'next/server';

export async function POST(req: NextRequest) {
  try {
    const { name, email, message } = await req.json();
    if (!email || !message) {
      return NextResponse.json(
        { error: 'Email and message are required.' },
        { status: 400 }
      );
    }

    // Store in DB or send email
    // e.g., await db.feedback.create({ data: { name, email, message } });

    return NextResponse.json({ success: true });
  } catch (error) {
    console.error('Feedback error:', error);
    return NextResponse.json(
      { error: 'Internal Server Error' },
      { status: 500 }
    );
  }
}
```

### 4.3 LLM Streaming
```typescript
// lib/openai.ts
import { createParser } from 'eventsource-parser';

interface OpenAIRequest {
  model: string;
  messages: { role: string; content: string }[];
  temperature?: number;
  max_tokens?: number;
}

export async function OpenAIStream(options: OpenAIRequest) {
  const res = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPENAI_API_KEY || ''}`,
    },
    body: JSON.stringify({ ...options, stream: true }),
  });

  if (!res.ok || !res.body) {
    throw new Error(`OpenAI API Error: ${await res.text()}`);
  }

  const encoder = new TextEncoder();
  const decoder = new TextDecoder();

  const stream = new ReadableStream({
    async start(controller) {
      const parser = createParser((event) => {
        if (event.type === 'event') {
          const data = event.data;
          if (data === '[DONE]') {
            controller.close();
            return;
          }
          try {
            const json = JSON.parse(data);
            const text = json.choices[0]?.delta?.content || '';
            if (text) {
              controller.enqueue(encoder.encode(text));
            }
          } catch (err) {
            controller.error(err);
          }
        }
      });

      for await (const chunk of res.body as any) {
        parser.feed(decoder.decode(chunk));
      }
    },
  });

  return stream;
}
```

### 4.4 Frontend Components

We'll use Chakra UI, a comprehensive component library that provides:

- **Accessible Components**: Built following WAI-ARIA standards
- **Composable System**: Mix and match components
- **Theme-Aware**: Light/dark mode support
- **Motion Support**: Built-in animations
- **React Server Components**: For optimal performance

#### Component Architecture
```typescript
// app/components/Chat/layout.tsx
import { Suspense } from 'react';
import { ChakraProvider, Spinner, Center } from '@chakra-ui/react';
import { ChatProvider } from './ChatContext';

export default function ChatLayout({ children }) {
  return (
    <ChakraProvider>
      <ChatProvider>
        <Suspense fallback={
          <Center h="100vh">
            <Spinner size="xl" color="blue.500" />
          </Center>
        }>
          {children}
        </Suspense>
      </ChatProvider>
    </ChakraProvider>
  );
}

// app/components/Chat/ChatWindow.tsx
'use client';

import { useState } from 'react';
import {
  VStack,
  Card,
  CardBody,
  Container,
  useColorModeValue,
} from '@chakra-ui/react';
import { motion, AnimatePresence } from 'framer-motion';
import { useChat } from './ChatContext';
import { ChatInput } from './ChatInput';
import { MessageBubble } from './MessageBubble';

const MotionVStack = motion(VStack);

export function ChatWindow() {
  const { messages, sendMessage } = useChat();
  const [isTyping, setIsTyping] = useState(false);
  const bg = useColorModeValue('white', 'gray.800');

  return (
    <Container maxW="2xl" h="600px">
      <Card h="full" bg={bg} shadow="xl">
        <CardBody
          display="flex"
          flexDirection="column"
          overflowY="auto"
          css={{
            '&::-webkit-scrollbar': { width: '4px' },
            '&::-webkit-scrollbar-track': { background: 'transparent' },
            '&::-webkit-scrollbar-thumb': { background: 'gray.200' },
          }}
        >
          <AnimatePresence>
            <MotionVStack spacing={4} align="stretch" flex={1}>
              {messages.map((msg, i) => (
                <motion.div
                  key={i}
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ opacity: 1, y: 0 }}
                  exit={{ opacity: 0, y: -20 }}
                >
                  <MessageBubble message={msg} />
                </motion.div>
              ))}
              {isTyping && <TypingIndicator />}
            </MotionVStack>
          </AnimatePresence>
        </CardBody>
        <ChatInput onSend={sendMessage} onTypingChange={setIsTyping} />
      </Card>
    </Container>
  );
}

// app/components/Chat/MessageBubble.tsx
import { memo } from 'react';
import {
  Box,
  Text,
  useColorModeValue,
  Alert,
  AlertIcon,
} from '@chakra-ui/react';
import { motion } from 'framer-motion';
import { marked } from 'marked';
import DOMPurify from 'dompurify';

interface MessageProps {
  message: {
    role: string;
    content: string;
  };
}

const MotionBox = motion(Box);

export const MessageBubble = memo(function MessageBubble({ message }: MessageProps) {
  const isUser = message.role === 'user';
  const sanitizedHtml = DOMPurify.sanitize(marked(message.content));
  
  const bg = useColorModeValue(
    isUser ? 'blue.500' : 'gray.100',
    isUser ? 'blue.400' : 'gray.700'
  );
  const color = useColorModeValue(
    isUser ? 'white' : 'gray.900',
    isUser ? 'white' : 'gray.100'
  );

  return (
    <MotionBox
      display="flex"
      justifyContent={isUser ? 'flex-end' : 'flex-start'}
      initial={{ scale: 0.95, opacity: 0 }}
      animate={{ scale: 1, opacity: 1 }}
    >
      <Box
        maxW="80%"
        bg={bg}
        color={color}
        px={4}
        py={2}
        borderRadius="xl"
      >
        <Text
          dangerouslySetInnerHTML={{ __html: sanitizedHtml }}
          sx={{
            'p': { margin: 0 },
            'a': { color: 'blue.200', textDecoration: 'underline' },
            'code': { bg: 'gray.700', px: 1, borderRadius: 'sm' },
          }}
        />
      </Box>
    </MotionBox>
  );
});

// app/components/Chat/ChatInput.tsx
'use client';

import { useState, useRef } from 'react';
import {
  Box,
  Textarea,
  IconButton,
  HStack,
  useColorModeValue,
} from '@chakra-ui/react';
import { FiSend } from 'react-icons/fi';

interface ChatInputProps {
  onSend: (message: string) => Promise<void>;
  onTypingChange: (isTyping: boolean) => void;
}

export function ChatInput({ onSend, onTypingChange }: ChatInputProps) {
  const [input, setInput] = useState('');
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  const borderColor = useColorModeValue('gray.200', 'gray.600');

  const handleSubmit = async (e?: React.FormEvent) => {
    e?.preventDefault();
    if (!input.trim()) return;

    onTypingChange(true);
    setInput('');
    await onSend(input);
    onTypingChange(false);
  };

  return (
    <Box p={4} borderTop="1px" borderColor={borderColor}>
      <HStack spacing={2}>
        <Textarea
          ref={textareaRef}
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type your message..."
          size="sm"
          resize="none"
          rows={1}
          maxRows={4}
          onKeyDown={(e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
              e.preventDefault();
              handleSubmit();
            }
          }}
        />
        <IconButton
          aria-label="Send message"
          icon={<FiSend />}
          colorScheme="blue"
          onClick={() => handleSubmit()}
          isDisabled={!input.trim()}
        />
      </HStack>
    </Box>
  );
}

// app/components/Chat/TypingIndicator.tsx
import { HStack, Circle } from '@chakra-ui/react';
import { motion } from 'framer-motion';

const MotionCircle = motion(Circle);

export function TypingIndicator() {
  return (
    <HStack spacing={2} p={4}>
      {[0, 1, 2].map((i) => (
        <MotionCircle
          key={i}
          size="2"
          bg="gray.400"
          animate={{ scale: [1, 1.2, 1] }}
          transition={{
            duration: 1,
            repeat: Infinity,
            delay: i * 0.2,
          }}
        />
      ))}
    </HStack>
  );
}

// app/components/Chat/ChatContext.tsx
'use client';

import { createContext, useContext, useReducer, useCallback } from 'react';
import { useToast } from '@chakra-ui/react';

interface Message {
  role: string;
  content: string;
}

interface ChatState {
  messages: Message[];
}

interface ChatContextType extends ChatState {
  sendMessage: (content: string) => Promise<void>;
}

const ChatContext = createContext<ChatContextType | null>(null);

export function ChatProvider({ children }) {
  const [state, dispatch] = useReducer(chatReducer, { messages: [] });
  const toast = useToast();

  const sendMessage = useCallback(async (content: string) => {
    dispatch({ type: 'ADD_MESSAGE', message: { role: 'user', content } });

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        body: JSON.stringify({ userMessages: [...state.messages, { role: 'user', content }] }),
      });

      if (!response.ok) throw new Error('Failed to send message');
      if (!response.body) return;

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let assistantResponse = '';

      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        assistantResponse += decoder.decode(value);
        dispatch({
          type: 'UPDATE_LAST_ASSISTANT_MESSAGE',
          content: assistantResponse,
        });
      }
    } catch (error) {
      toast({
        title: 'Error',
        description: 'Failed to send message. Please try again.',
        status: 'error',
        duration: 5000,
        isClosable: true,
      });
    }
  }, [state.messages, toast]);

  return (
    <ChatContext.Provider value={{ ...state, sendMessage }}>
      {children}
    </ChatContext.Provider>
  );
}

export function useChat() {
  const context = useContext(ChatContext);
  if (!context) throw new Error('useChat must be used within ChatProvider');
  return context;
}

function chatReducer(state: ChatState, action: any): ChatState {
  switch (action.type) {
    case 'ADD_MESSAGE':
      return {
        ...state,
        messages: [...state.messages, action.message],
      };
    case 'UPDATE_LAST_ASSISTANT_MESSAGE':
      return {
        ...state,
        messages: [
          ...state.messages.slice(0, -1),
          { role: 'assistant', content: action.content },
        ],
      };
    default:
      return state;
  }
}
```

This modern component architecture includes:

1. **Accessible Components**:
   - Radix UI ScrollArea for smooth scrolling
   - ARIA-compliant form controls
   - Keyboard navigation support

2. **Fluid Animations**:
   - Message entrance/exit animations
   - Typing indicator animation
   - Button press feedback
   - Smooth height transitions

3. **Smart Features**:
   - Markdown rendering with sanitization
   - Auto-resizing textarea
   - Enter to send (with shift+enter for new line)
   - Real-time typing indicator

4. **Performance Optimizations**:
   - React Server Components where possible
   - Memoized message bubbles
   - Efficient context updates
   - Suspense boundaries for loading states

5. **Developer Experience**:
   - Type-safe components
   - Modular architecture
   - Reusable hooks and utilities
   - Clear separation of concerns

Required dependencies:
```json
{
  "dependencies": {
    "@chakra-ui/react": "^2.8.0",
    "@emotion/react": "^11.11.1",
    "@emotion/styled": "^11.11.0",
    "framer-motion": "^10.16.4",
    "marked": "^9.1.2",
    "dompurify": "^3.0.6",
    "react-icons": "^4.11.0"
  }
}
```

## 5. Security & Privacy

### 5.1 API Security
- Rate limiting (optional): Use tools like Upstash Rate Limit for Next.js
- Input validation and sanitization
- HTTPS-only connections

### 5.2 Environment Variables
- OpenAI API Key stored securely in environment variables
- Never exposed on the client side

## 6. Deployment Strategy

### 6.1 Infrastructure
- Single repository deployed on Vercel
- Automatic HTTPS and edge functions
- Environment variables configured in Vercel project settings

### 6.2 Resume Hosting
- Store PDF in `public/` folder or use S3 bucket
- Link to it in the `BASE_PROMPT`

## 7. Testing Strategy

### 7.1 Unit Tests
- Test OpenAI streaming function
- Validate feedback submission with various inputs
- Mock API responses for consistent testing

### 7.2 Integration Tests
- End-to-end conversation flow
- Feedback submission process
- Resume link functionality

### 7.3 Manual Testing
- Deploy to test environment
- Verify streaming responses
- Test feedback collection

## 8. Monitoring & Analytics

### 8.1 Key Metrics
- Page visits and performance (Vercel Analytics)
- OpenAI token usage and costs
- Error rates and types
- Feedback submission tracking

### 8.2 Logging
- Server-side logs for debugging
- Client-side error tracking
- Usage analytics for optimization

## 9. Future Enhancements

### 9.1 Potential Improvements
1. **Conditional Context**
   - Split context by topic, inject relevant sections
2. **Database Integration**
   - Add robust feedback storage and management
3. **Authentication**
   - Secure admin features if needed
4. **UI/UX**
   - Polish chat interface and animations
5. **Multi-step Contact Flow**
   - Guided data collection for specific inquiries

---

This technical specification provides a streamlined approach to building JonaBot using Next.js Route Handlers and streaming responses, eliminating the need for WebSockets or separate servers while maintaining core functionality.

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: WORK_LOG.md
================
# JonaBot Implementation Work Log

## Completed Tasks ✅

### Core Infrastructure
- ✅ Set up Next.js 14 project with TypeScript
- ✅ Configured Chakra UI for styling
- ✅ Implemented dark mode support
- ✅ Set up environment variables

### API Implementation
- ✅ Created OpenAI streaming utility
- ✅ Implemented chat completion endpoint
- ✅ Implemented feedback submission endpoint
- ✅ Added error handling for API routes

### Chat Interface
- ✅ Created ChatContext for state management
- ✅ Implemented ChatWindow component
- ✅ Implemented ChatInput component with streaming support
- ✅ Implemented MessageBubble component with Markdown support
- ✅ Added animations and transitions
- ✅ Implemented auto-scrolling for new messages
- ✅ Added typing indicators
- ✅ Added message timestamps
- ✅ Added copy code button for code blocks
- ✅ Added avatar images for bot and user
- ✅ Improved message bubble layout with avatars
- ✅ Added loading states and error handling
  - ✅ Initial loading skeleton
  - ✅ Message sending states
  - ✅ Connection error handling
  - ✅ Input disabled states
  - ✅ Loading indicators

## Pending Tasks 📝

### Content & Configuration
- 📝 Customize base prompt with actual resume and project details
- 📝 Add resume PDF to public directory
- 📝 Configure project links and descriptions

### Feedback System
- 📝 Implement feedback storage solution
- 📝 Add feedback management interface
- 📝 Set up email notifications for feedback

### Testing
- 📝 Add unit tests for OpenAI streaming
- 📝 Add integration tests for chat flow
- 📝 Add end-to-end tests
- 📝 Test feedback submission process

### Security & Monitoring
- 📝 Implement rate limiting
- 📝 Add input validation and sanitization
- 📝 Set up logging system
- 📝 Configure analytics tracking

### UI/UX Improvements
- 📝 Add mobile responsiveness improvements
- 📝 Add message reactions/feedback
- 📝 Add chat history persistence
- 📝 Add voice input/output support

### Documentation
- 📝 Add API documentation
- 📝 Add deployment instructions
- 📝 Add contribution guidelines
- 📝 Add security policy

## Next Steps 🎯
1. Customize base prompt with actual content
2. Implement feedback storage solution
3. Add test suite
4. Improve documentation

## Known Issues 🐛
1. Need to handle network errors more gracefully
2. Need to implement proper rate limiting
3. Need to add proper input validation
